#!/usr/bin/env python
import pandas as pd
import os
import re

def clean_training_data():
    input_file = "C:/Users/NTHUILST/Ray/DL/data/training_data_improve.csv"
    output_file = "C:/Users/NTHUILST/Ray/DL/data/training_data_cleaned.csv"
    
    print("ğŸ§¹ è¨“ç·´æ•¸æ“šè‡ªå‹•æ¸…ç†å·¥å…·")
    
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {input_file}")
        return False
    
    df = pd.read_csv(input_file)
    original = len(df)
    print(f"ğŸ“¥ åŸå§‹æ•¸æ“š: {original} è¡Œ")
    
    # æª¢æ¸¬æ¬„ä½
    cols = {}
    possible = {
        'question': ['é¡Œç›®', 'question'],
        'option_A': ['é¸é …A', 'option_A'],
        'option_B': ['é¸é …B', 'option_B'],  
        'option_C': ['é¸é …C', 'option_C'],
        'option_D': ['é¸é …D', 'option_D'],
        'answer': ['æ­£ç¢ºç­”æ¡ˆ', 'answer'],
        'reasoning': ['æ¨ç†æ­£ç¢ºç­”æ¡ˆ', 'reasoning']
    }
    
    for field, names in possible.items():
        for name in names:
            if name in df.columns:
                cols[field] = name
                break
    
    if len(cols) < 6:
        print("âŒ ç¼ºå°‘å¿…éœ€æ¬„ä½")
        return False
    
    print("ğŸ”§ é–‹å§‹æ¸…ç†...")
    
    # 1. ç§»é™¤ç©ºç™½è¡Œ
    df = df.dropna(how='all')
    
    # 2. æ¸…ç†å¿…éœ€æ¬„ä½ç©ºå€¼
    required = ['question', 'option_A', 'option_B', 'option_C', 'option_D', 'answer']
    for field in required:
        if field in cols:
            col = cols[field]
            before = len(df)
            df = df.dropna(subset=[col])
            removed = before - len(df)
            if removed > 0:
                print(f"   {field}: ç§»é™¤ {removed} å€‹ç©ºå€¼")
    
    # 3. ä¿®å¾©ç­”æ¡ˆæ ¼å¼
    if 'answer' in cols:
        answer_col = cols['answer']
        def fix_answer(ans):
            if pd.isna(ans):
                return None
            ans_str = str(ans).strip().upper()
            ans_clean = re.sub(r'[^ABCD]', '', ans_str)
            if len(ans_clean) == 1 and ans_clean in ['A','B','C','D']:
                return ans_clean
            for letter in ['A','B','C','D']:
                if letter in ans_str:
                    return letter
            return None
        
        before_fix = len(df)
        df[answer_col] = df[answer_col].apply(fix_answer)
        df = df.dropna(subset=[answer_col])
        fixed = before_fix - len(df)
        if fixed > 0:
            print(f"   ç­”æ¡ˆæ ¼å¼: ä¿®å¾©/ç§»é™¤ {fixed} å€‹")
    
    # 4. æ¸…ç†æ–‡æœ¬å…§å®¹
    text_fields = ['question', 'option_A', 'option_B', 'option_C', 'option_D']
    for field in text_fields:
        if field in cols:
            col = cols[field]
            before = len(df)
            df = df[df[col].str.len() >= 3]  # ç§»é™¤éçŸ­å…§å®¹
            removed = before - len(df)
            if removed > 0:
                print(f"   {field}: ç§»é™¤ {removed} å€‹éçŸ­å…§å®¹")
            df[col] = df[col].str.strip()  # æ¸…ç†ç©ºæ ¼
    
    # 5. ç§»é™¤é‡è¤‡
    before_dup = len(df)
    df = df.drop_duplicates()
    dup_removed = before_dup - len(df)
    if dup_removed > 0:
        print(f"   ç§»é™¤ {dup_removed} å€‹é‡è¤‡è¡Œ")
    
    # 6. é‡ç½®ç´¢å¼•
    df = df.reset_index(drop=True)
    
    final = len(df)
    removed = original - final
    retention = (final / original) * 100
    
    print(f"\nğŸ“Š æ¸…ç†çµæœ:")
    print(f"   åŸå§‹: {original} è¡Œ")
    print(f"   æ¸…ç†å¾Œ: {final} è¡Œ")
    print(f"   ç§»é™¤: {removed} è¡Œ")
    print(f"   ä¿ç•™ç‡: {retention:.1f}%")
    
    # ä¿å­˜æ¸…ç†å¾Œçš„æ•¸æ“š
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"ğŸ’¾ å·²ä¿å­˜æ¸…ç†å¾Œæ•¸æ“š: {output_file}")
    
    if final < original * 0.5:
        print("âš ï¸  è­¦å‘Š: è¶…é50%çš„æ•¸æ“šè¢«ç§»é™¤")
        return False
    
    print("âœ… æ•¸æ“šæ¸…ç†å®Œæˆï¼")
    return True, output_file

if __name__ == "__main__":
    result = clean_training_data()
    if result:
        print("\nğŸ¯ ç¾åœ¨å¯ä»¥ä½¿ç”¨æ¸…ç†å¾Œçš„æ•¸æ“šè¨“ç·´:")
        print("   ä¿®æ”¹è¨“ç·´è…³æœ¬ä¸­çš„æ–‡ä»¶è·¯å¾‘ç‚º: training_data_cleaned.csv")
    else:
        print("\nâŒ æ•¸æ“šæ¸…ç†å¤±æ•—")
