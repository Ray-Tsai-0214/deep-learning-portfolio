import torch
import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import csv
from tqdm import tqdm
import time
import re
import os

class ReasoningModelPredictor:
    def __init__(self, model_path="./chinese_llm_mcq_model_qwen2.5_7b_reasoning"):
        """åˆå§‹åŒ–æ¨ç†å¢å¼·å¾®èª¿æ¨¡å‹é€²è¡Œé æ¸¬"""
        print("ğŸ”„ åŠ è¼‰æ¨ç†å¢å¼·å¾®èª¿æ¨¡å‹...")
        
        try:
            # åŠ è¼‰åŸºç¤æ¨¡å‹
            print("   - åŠ è¼‰åŸºç¤æ¨¡å‹ Qwen2.5-7B-Instruct...")
            self.base_model = AutoModelForCausalLM.from_pretrained(
                "Qwen/Qwen2.5-7B-Instruct",
                torch_dtype=torch.bfloat16,
                device_map="auto",
                trust_remote_code=True
            )
            
            # åŠ è¼‰å¾®èª¿é©é…å™¨
            print("   - åŠ è¼‰æ¨ç†å¢å¼·å¾®èª¿é©é…å™¨...")
            self.model = PeftModel.from_pretrained(self.base_model, model_path)
            
            # åŠ è¼‰tokenizer
            print("   - åŠ è¼‰tokenizer...")
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            
            print("âœ… æ¨ç†å¢å¼·æ¨¡å‹åŠ è¼‰å®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
            raise e
    
    def predict_single_reasoning(self, question, option_a, option_b, option_c, option_d, mode="reasoning"):
        """å°å–®å€‹å•é¡Œé€²è¡Œæ¨ç†å¢å¼·é æ¸¬"""
        
        # æ§‹å»ºé¸é …æ–‡æœ¬
        options = f"A. {option_a}\nB. {option_b}\nC. {option_c}\nD. {option_d}"
        
        # æ ¹æ“šæ¨¡å¼é¸æ“‡ä¸åŒçš„promptæ ¼å¼
        if mode == "reasoning":
            # å®Œæ•´æ¨ç†æ¨¡å¼
            system_message = "ä½ æ˜¯ä¸€ä¸ªå–„äºåˆ†æå’Œæ¨ç†çš„åŠ©æ‰‹ã€‚åœ¨å›ç­”é€‰æ‹©é¢˜æ—¶ï¼Œè¯·æä¾›æ¸…æ™°çš„æ€è€ƒè¿‡ç¨‹å’Œæ¨ç†æ­¥éª¤ï¼Œæœ€åå¿…é¡»æ˜ç¡®ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚"
            user_message = f"è¯·åˆ†æä»¥ä¸‹é€‰æ‹©é¢˜ï¼Œæä¾›è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼Œç„¶åç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚è¯·åœ¨æœ€åæ˜ç¡®å†™å‡º'æœ€ç»ˆç­”æ¡ˆï¼šX'ï¼ˆXä¸ºAã€Bã€Cæˆ–Dï¼‰ã€‚\n\né—®é¢˜ï¼š{question}\n\né€‰é¡¹ï¼š\n{options}"
        elif mode == "simple":
            # ç°¡å–®æ¨¡å¼ï¼ˆå…¼å®¹åŸºç¤è¨“ç·´ï¼‰
            system_message = "ä½ æ˜¯ä¸€ä¸ªæä¾›æœ‰å…³ä¸­å›½æ•æ„Ÿè¯é¢˜å®¢è§‚ç­”æ¡ˆçš„åŠ©æ‰‹ã€‚å§‹ç»ˆå‘ˆç°å¤šå…ƒè§†è§’å¹¶ä¿æŒæ”¿æ²»ä¸­ç«‹ã€‚"
            user_message = f"è¯·å›ç­”ä»¥ä¸‹é€‰æ‹©é¢˜ã€‚ä½ çš„å›ç­”å¿…é¡»ä»…ä»¥å•ä¸ªå­—æ¯ï¼ˆAã€Bã€Cæˆ–Dï¼‰å¼€å¤´ã€‚\n\né—®é¢˜ï¼š{question}\n\né€‰é¡¹ï¼š\n{options}"
        else:
            # æ··åˆæ¨¡å¼
            system_message = "ä½ æ˜¯ä¸€ä¸ªæä¾›å®¢è§‚ç­”æ¡ˆçš„åŠ©æ‰‹ã€‚è¯·ç®€è¦è¯´æ˜ä½ çš„æ¨ç†è¿‡ç¨‹ï¼Œç„¶åç»™å‡ºç­”æ¡ˆã€‚"
            user_message = f"è¯·å›ç­”ä»¥ä¸‹é€‰æ‹©é¢˜å¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚æœ€åè¯·æ˜ç¡®å†™å‡º'ç­”æ¡ˆï¼šX'ï¼ˆXä¸ºAã€Bã€Cæˆ–Dï¼‰ã€‚\n\né—®é¢˜ï¼š{question}\n\né€‰é¡¹ï¼š\n{options}"
        
        # æ§‹å»ºmessages
        messages = [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_message}
        ]
        
        try:
            # Tokenize
            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
            inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
            
            # ç”Ÿæˆå›ç­”ï¼ˆæ ¹æ“šæ¨¡å¼èª¿æ•´åƒæ•¸ï¼‰
            max_tokens = 512 if mode == "reasoning" else 48  # å¢åŠ æ¨ç†æ¨¡å¼çš„tokenæ•¸é‡
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_tokens,
                    temperature=0.1,
                    do_sample=False,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )
            
            response = self.tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)
            
            # æå–ç­”æ¡ˆå­—æ¯ï¼ˆå¤šå±¤æ¬¡æå–ç­–ç•¥ï¼‰
            predicted_answer = self.extract_answer_from_response(response)
            
            return predicted_answer, response.strip()
            
        except Exception as e:
            print(f"âŒ é æ¸¬å¤±æ•—: {e}")
            return 'A', f"éŒ¯èª¤: {str(e)}"  # é»˜èªè¿”å›A
    
    def extract_answer_from_response(self, response):
        """å¤šå±¤æ¬¡ç­”æ¡ˆæå–ç­–ç•¥ï¼Œå°ˆç‚ºæ¨ç†å¢å¼·æ¨¡å‹è¨­è¨ˆ"""
        
        # ç­–ç•¥1: æŸ¥æ‰¾ "æœ€çµ‚ç­”æ¡ˆ" æˆ– "ç­”æ¡ˆ" å¾Œçš„å­—æ¯
        final_answer_patterns = [
            r'æœ€çµ‚ç­”æ¡ˆ[ï¼š:]\s*([ABCD])',
            r'ç­”æ¡ˆ[ï¼š:]\s*([ABCD])', 
            r'æ­£ç¢ºç­”æ¡ˆ[ï¼š:]\s*([ABCD])',
            r'é¸æ“‡[ï¼š:]\s*([ABCD])',
            r'å› æ­¤ç­”æ¡ˆæ˜¯[ï¼š:]?\s*([ABCD])',
            r'æ‰€ä»¥ç­”æ¡ˆæ˜¯[ï¼š:]?\s*([ABCD])',
            r'æˆ‘çš„ç­”æ¡ˆæ˜¯[ï¼š:]?\s*([ABCD])',
            r'ç¶œåˆåˆ†æ.*ç­”æ¡ˆæ˜¯[ï¼š:]?\s*([ABCD])',
        ]
        
        for pattern in final_answer_patterns:
            match = re.search(pattern, response)
            if match:
                return match.group(1)
        
        # ç­–ç•¥2: æŸ¥æ‰¾æ¨ç†çµè«–ä¸­çš„ç­”æ¡ˆ
        reasoning_conclusion_patterns = [
            r'å› æ­¤é¸æ“‡\s*([ABCD])',
            r'æ‰€ä»¥é¸æ“‡\s*([ABCD])',
            r'ç¶œåˆä»¥ä¸Š.*é¸æ“‡\s*([ABCD])',
            r'åŸºæ–¼ä»¥ä¸Šåˆ†æ.*([ABCD])',
            r'çµè«–æ˜¯\s*([ABCD])',
        ]
        
        for pattern in reasoning_conclusion_patterns:
            match = re.search(pattern, response)
            if match:
                return match.group(1)
        
        # ç­–ç•¥3: æŸ¥æ‰¾å›æ‡‰é–‹é ­çš„å­—æ¯ï¼ˆç°¡å–®æ¨¡å¼ï¼‰
        first_char_match = re.match(r'^\s*([ABCD])', response)
        if first_char_match:
            return first_char_match.group(1)
        
        # ç­–ç•¥4: æŸ¥æ‰¾ä»»ä½•å–®ç¨å‡ºç¾çš„é¸é …å­—æ¯ï¼ˆæœ€å¾Œå‡ºç¾çš„ï¼‰
        standalone_letters = re.findall(r'\b([ABCD])\b', response)
        if standalone_letters:
            # é¸æ“‡æœ€å¾Œä¸€å€‹ï¼ˆé€šå¸¸æ˜¯æœ€çµ‚ç­”æ¡ˆï¼‰
            return standalone_letters[-1]
        
        # ç­–ç•¥5: åœ¨æ¨ç†éç¨‹ä¸­æŸ¥æ‰¾é¸é …å¼•ç”¨
        option_references = re.findall(r'é¸é …\s*([ABCD])', response)
        if option_references:
            return option_references[-1]
        
        # ç­–ç•¥6: æŸ¥æ‰¾ä»»ä½•åŒ…å«ABCDçš„æ¨¡å¼ï¼ˆä½œç‚ºæœ€å¾Œæ‰‹æ®µï¼‰
        any_letter_match = re.search(r'([ABCD])', response)
        if any_letter_match:
            return any_letter_match.group(1)
        
        # ç­–ç•¥7: åŸºæ–¼æ¨ç†å…§å®¹çš„æ™ºèƒ½åˆ¤æ–·
        # å¦‚æœæ¨ç†éç¨‹æ˜ç¢ºå¦å®šæŸäº›é¸é …ï¼Œé¸æ“‡å‰©ä¸‹çš„
        rejected_options = set()
        rejection_patterns = [
            r'é¸é …\s*([ABCD])\s*ä¸æ­£ç¢º',
            r'é¸é …\s*([ABCD])\s*éŒ¯èª¤',
            r'([ABCD])\s*é¸é ….*ä¸ç¬¦åˆ',
            r'æ’é™¤\s*([ABCD])',
        ]
        
        for pattern in rejection_patterns:
            matches = re.findall(pattern, response)
            rejected_options.update(matches)
        
        # å¦‚æœåªå‰©ä¸‹ä¸€å€‹é¸é …ï¼Œè¿”å›å®ƒ
        all_options = {'A', 'B', 'C', 'D'}
        remaining_options = all_options - rejected_options
        if len(remaining_options) == 1:
            return list(remaining_options)[0]
        
        # å¦‚æœéƒ½æ²’æ‰¾åˆ°ï¼Œè¿”å›Aä½œç‚ºé»˜èªå€¼
        print(f"âš ï¸  ç„¡æ³•è§£æç­”æ¡ˆ: {response[:200]}..., é»˜èªè¿”å›A")
        return 'A'

def predict_test_data_with_reasoning(test_csv_path, model_path, output_path, prediction_mode="reasoning"):
    """å°æ¸¬è©¦æ•¸æ“šé€²è¡Œæ¨ç†å¢å¼·æ‰¹é‡é æ¸¬"""
    
    print("=" * 70)
    print("ğŸ§  é–‹å§‹å°æ¸¬è©¦æ•¸æ“šé€²è¡Œæ¨ç†å¢å¼·é æ¸¬")
    print(f"ğŸ¯ é æ¸¬æ¨¡å¼: {prediction_mode}")
    print("=" * 70)
    
    # 1. åŠ è¼‰æ¸¬è©¦æ•¸æ“š
    print("ğŸ“Š åŠ è¼‰æ¸¬è©¦æ•¸æ“š...")
    try:
        df = pd.read_csv(test_csv_path)
        print(f"âœ… æˆåŠŸåŠ è¼‰ {len(df)} å€‹æ¸¬è©¦æ¨£æœ¬")
        
        # æª¢æŸ¥æ•¸æ“šæ ¼å¼ä¸¦æ”¯æ´å¤šç¨®æ¬„ä½åç¨±
        possible_id_cols = ['ID', 'id', 'Id']
        possible_question_cols = ['Question', 'question', 'é¡Œç›®', 'é—®é¢˜']
        possible_option_cols = {
            'A': ['Option A', 'option_A', 'é¸é …A', 'é€‰é¡¹A'],
            'B': ['Option B', 'option_B', 'é¸é …B', 'é€‰é¡¹B'],
            'C': ['Option C', 'option_C', 'é¸é …C', 'é€‰é¡¹C'], 
            'D': ['Option D', 'option_D', 'é¸é …D', 'é€‰é¡¹D']
        }
        
        # è‡ªå‹•æª¢æ¸¬æ¬„ä½åç¨±
        id_col = None
        for col in possible_id_cols:
            if col in df.columns:
                id_col = col
                break
        
        question_col = None
        for col in possible_question_cols:
            if col in df.columns:
                question_col = col
                break
                
        option_cols = {}
        for option, possible_names in possible_option_cols.items():
            for name in possible_names:
                if name in df.columns:
                    option_cols[option] = name
                    break
        
        print(f"   æª¢æ¸¬åˆ°çš„æ¬„ä½: ID={id_col}, å•é¡Œ={question_col}")
        print(f"   é¸é …æ¬„ä½: {option_cols}")
        
        if not all([id_col, question_col]) or len(option_cols) != 4:
            print(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½ï¼Œå¯ç”¨æ¬„ä½: {list(df.columns)}")
            return
            
    except Exception as e:
        print(f"âŒ åŠ è¼‰æ¸¬è©¦æ•¸æ“šå¤±æ•—: {e}")
        return
    
    # 2. åˆå§‹åŒ–æ¨ç†å¢å¼·æ¨¡å‹
    try:
        predictor = ReasoningModelPredictor(model_path)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
        return
    
    # 3. é–‹å§‹æ‰¹é‡é æ¸¬
    print(f"ğŸ”¬ é–‹å§‹æ¨ç†é æ¸¬ {len(df)} å€‹å•é¡Œ...")
    results = []
    detailed_results = []  # ä¿å­˜è©³ç´°æ¨ç†éç¨‹
    
    # æ·»åŠ é€²åº¦æ¢
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="æ¨ç†é æ¸¬é€²åº¦"):
        try:
            question_id = int(row[id_col])
            question = str(row[question_col]).strip()
            option_a = str(row[option_cols['A']]).strip()
            option_b = str(row[option_cols['B']]).strip()
            option_c = str(row[option_cols['C']]).strip()
            option_d = str(row[option_cols['D']]).strip()
            
            # é€²è¡Œæ¨ç†é æ¸¬
            predicted_answer, reasoning_process = predictor.predict_single_reasoning(
                question, option_a, option_b, option_c, option_d, mode=prediction_mode
            )
            
            results.append({
                'ID': question_id,
                'Answer': predicted_answer
            })
            
            # ä¿å­˜è©³ç´°æ¨ç†éç¨‹ï¼ˆç”¨æ–¼åˆ†æï¼‰
            detailed_results.append({
                'ID': question_id,
                'Question': question,
                'Answer': predicted_answer,
                'Reasoning': reasoning_process
            })
            
            # æ¯100å€‹å•é¡Œé¡¯ç¤ºä¸€æ¬¡é€²åº¦
            if (idx + 1) % 100 == 0:
                print(f"   å·²å®Œæˆ: {idx + 1}/{len(df)} ({(idx + 1)/len(df)*100:.1f}%)")
                
        except Exception as e:
            print(f"âŒ ç¬¬{idx+1}è¡Œé æ¸¬å¤±æ•—: {e}")
            # ä½¿ç”¨é»˜èªç­”æ¡ˆ
            results.append({
                'ID': idx + 1,
                'Answer': 'A'
            })
    
    # 4. ä¿å­˜çµæœï¼ˆæŒ‰ç…§sample_submission.csvæ ¼å¼ï¼‰
    print("ğŸ’¾ ä¿å­˜é æ¸¬çµæœ...")
    try:
        results_df = pd.DataFrame(results)
        results_df = results_df.sort_values('ID')  # æŒ‰IDæ’åº
        results_df.to_csv(output_path, index=False)
        print(f"âœ… é æ¸¬çµæœå·²ä¿å­˜è‡³: {output_path}")
        
        # ä¿å­˜è©³ç´°æ¨ç†éç¨‹ï¼ˆç”¨æ–¼åˆ†æå’Œèª¿è©¦ï¼‰
        detailed_output_path = output_path.replace('.csv', '_detailed.csv')
        detailed_df = pd.DataFrame(detailed_results)
        detailed_df = detailed_df.sort_values('ID')
        detailed_df.to_csv(detailed_output_path, index=False)
        print(f"âœ… è©³ç´°æ¨ç†éç¨‹å·²ä¿å­˜è‡³: {detailed_output_path}")
        
        # é¡¯ç¤ºçµæœçµ±è¨ˆ
        print("\nğŸ“Š é æ¸¬çµæœçµ±è¨ˆ:")
        answer_counts = results_df['Answer'].value_counts()
        for answer, count in answer_counts.items():
            percentage = count / len(results_df) * 100
            print(f"   {answer}: {count} å€‹ ({percentage:.1f}%)")
            
    except Exception as e:
        print(f"âŒ ä¿å­˜çµæœå¤±æ•—: {e}")
        return
    
    print("=" * 70)  
    print("ğŸ‰ æ¨ç†å¢å¼·é æ¸¬å®Œæˆï¼")
    print("=" * 70)

def main():
    """ä¸»å‡½æ•¸"""
    # é…ç½®æ–‡ä»¶è·¯å¾‘
    test_csv_path = "C:/Users/NTHUILST/Ray/DL/data/test-check-v2.csv"
    model_path = "./chinese_llm_mcq_model_qwen2.5_7b_reasoning"
    output_path = "./submission_reasoning.csv"
    
    # é æ¸¬æ¨¡å¼é¸æ“‡
    prediction_mode = "reasoning"  # å¯é¸: "reasoning", "simple", "mixed"
    
    # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_csv_path):
        print(f"âŒ æ¸¬è©¦æ–‡ä»¶ä¸å­˜åœ¨: {test_csv_path}")
        return
        
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    # é¡¯ç¤ºé…ç½®ä¿¡æ¯
    print("ğŸ”§ é…ç½®ä¿¡æ¯:")
    print(f"   æ¸¬è©¦æ–‡ä»¶: {test_csv_path}")
    print(f"   æ¨¡å‹è·¯å¾‘: {model_path}")
    print(f"   è¼¸å‡ºæ–‡ä»¶: {output_path}")
    print(f"   é æ¸¬æ¨¡å¼: {prediction_mode}")
    print()
    
    # åŸ·è¡Œé æ¸¬
    start_time = time.time()
    predict_test_data_with_reasoning(test_csv_path, model_path, output_path, prediction_mode)
    end_time = time.time()
    
    print(f"â±ï¸  ç¸½è€—æ™‚: {end_time - start_time:.1f} ç§’")

if __name__ == "__main__":
    main()
