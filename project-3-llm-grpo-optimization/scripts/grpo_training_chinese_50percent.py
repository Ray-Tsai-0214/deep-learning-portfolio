#!/usr/bin/env python3
"""
GRPOè¨“ç·´è…³æœ¬ - ä¸­æ–‡æ¨ç†æ•¸æ“š50%å­é›†
å°ˆé–€ç”¨æ–¼Kaggle #3: GRPO with Reasoningè¨“ç·´

ä¸»è¦ç‰¹è‰²:
- Group Relative Policy Optimization (GRPO)
- ä¸­æ–‡æ•æ„Ÿè­°é¡Œæ¨ç†èƒ½åŠ›è¨“ç·´
- ä¸­ç«‹æ€§æ„ŸçŸ¥çš„çå‹µå‡½æ•¸
- 40å°æ™‚é•·æ™‚é–“ç©©å®šè¨“ç·´
"""
#!/usr/bin/env python3
"""
å®Œå…¨ä¿®å¾©ç‰ˆGRPOè¨“ç·´è…³æœ¬ - è§£æ±ºmultiprocessing pickleå•é¡Œ
Complete Fixed GRPO Training Script for Chinese LLM Reasoning
"""

import os
import sys
import json
import yaml
import logging
import torch
import random
import pandas as pd
import numpy as np
import re
from datetime import datetime
from typing import Dict, List, Tuple, Any
from tqdm import tqdm
import traceback

# æ ¸å¿ƒMLåº«
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments
)
from datasets import Dataset
from trl import GRPOTrainer, GRPOConfig
from peft import LoraConfig, get_peft_model

# ç›£æ§å’Œè¨˜éŒ„
import wandb

# ä¸­æ–‡æ¨¡å‹æ˜ å°„
CHINESE_MODELS = {
    "qwen2.5_7b": "Qwen/Qwen2.5-7B-Instruct",
    "chatglm3_6b": "THUDM/chatglm3-6b",
    "baichuan2_7b": "baichuan-inc/Baichuan2-7B-Chat",
    "internlm2_7b": "internlm/internlm2-chat-7b"
}

# å…¨å±€å®šç¾© data collator ä»¥æ”¯æŒå¤šé€²ç¨‹
def global_data_collator(features):
    """å…¨å±€æ•¸æ“šæ”¶é›†å™¨ï¼Œæ”¯æŒå¤šé€²ç¨‹åºåˆ—åŒ–"""
    # é€™æ˜¯ä¸€å€‹ç°¡å–®çš„å¯¦ç¾ï¼Œå¯ä»¥æ ¹æ“šéœ€è¦è‡ªå®šç¾©
    return features

# è¨­ç½®æ—¥èªŒ
def setup_logging():
    """è¨­ç½®æ—¥èªŒç³»çµ±"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # å‰µå»ºlogsç›®éŒ„
    os.makedirs("/home/ubuntu/DL/kaggle#3/logs", exist_ok=True)
    
    # é…ç½®ä¸»æ—¥èªŒ
    main_log_file = f"/home/ubuntu/DL/kaggle#3/logs/grpo_training_{timestamp}.log"
    progress_log_file = f"/home/ubuntu/DL/kaggle#3/logs/training_progress_{timestamp}.log"
    error_log_file = f"/home/ubuntu/DL/kaggle#3/logs/training_errors_{timestamp}.log"
    
    # é…ç½®æ ¹æ—¥èªŒå™¨
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(main_log_file),
            logging.StreamHandler()
        ]
    )
    
    logger = logging.getLogger(__name__)
    
    # æ·»åŠ é€²åº¦æ—¥èªŒè™•ç†å™¨
    progress_handler = logging.FileHandler(progress_log_file)
    progress_handler.setLevel(logging.INFO)
    logger.addHandler(progress_handler)
    
    # æ·»åŠ éŒ¯èª¤æ—¥èªŒè™•ç†å™¨
    error_handler = logging.FileHandler(error_log_file)
    error_handler.setLevel(logging.ERROR)
    logger.addHandler(error_handler)
    
    # è¿”å›æ—¥èªŒæ–‡ä»¶è·¯å¾‘
    return logger, main_log_file, progress_log_file, error_log_file

def load_config(config_path: str) -> Dict:
    """è¼‰å…¥é…ç½®æ–‡ä»¶ - å¢åŠ é¡å‹ä¿®å¾©"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info(f"ğŸ“– Loading configuration from: {config_path}")
        
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ä¿®å¾©æ•¸æ“šé¡å‹ - ç¢ºä¿é—œéµåƒæ•¸æ˜¯æ­£ç¢ºçš„é¡å‹
        if 'training' in config:
            training_config = config['training']
            
            # ä¿®å¾©å­¸ç¿’ç‡é¡å‹
            if 'learning_rate' in training_config:
                lr = training_config['learning_rate']
                if isinstance(lr, str):
                    try:
                        training_config['learning_rate'] = float(lr)
                        logger.info(f"ğŸ”§ Fixed learning_rate type: {lr} -> {training_config['learning_rate']}")
                    except ValueError:
                        logger.warning(f"âš ï¸ Could not convert learning_rate '{lr}' to float, using default 5e-5")
                        training_config['learning_rate'] = 5e-5
            
            # ä¿®å¾©å…¶ä»–å¯èƒ½çš„é¡å‹å•é¡Œ
            int_params = ['batch_size', 'gradient_accumulation_steps', 'num_epochs', 'warmup_steps', 
                         'logging_steps', 'save_steps', 'eval_steps']
            for param in int_params:
                if param in training_config and isinstance(training_config[param], str):
                    try:
                        training_config[param] = int(training_config[param])
                        logger.info(f"ğŸ”§ Fixed {param} type: str -> int")
                    except ValueError:
                        logger.warning(f"âš ï¸ Could not convert {param} to int")
            
            # ä¿®å¾©æµ®é»æ•¸åƒæ•¸
            if 'data' in config:
                float_params = ['train_test_split']
                for param in float_params:
                    if param in config['data'] and isinstance(config['data'][param], str):
                        try:
                            config['data'][param] = float(config['data'][param])
                            logger.info(f"ğŸ”§ Fixed {param} type: str -> float")
                        except ValueError:
                            logger.warning(f"âš ï¸ Could not convert {param} to float")
        
        # å¼·åˆ¶å•Ÿç”¨å¿«é€Ÿæ¸¬è©¦æ¨¡å¼
        if 'training' not in config:
            config['training'] = {}
        
        config['training']['quick_test'] = True
        config['training']['sample_ratio'] = 0.5  # åªç”¨1%æ•¸æ“šå¿«é€Ÿæ¸¬è©¦
        
        # ã€é—œéµä¿®å¾©ã€‘å¼·åˆ¶è¨­ç½® num_workers ç‚º 0 ä»¥é¿å… pickle å•é¡Œ
        if 'system' not in config:
            config['system'] = {}
        config['system']['num_workers'] = 0
        
        logger.info("âœ… Configuration loaded and fixed successfully")
        logger.info(f"ğŸ” é…ç½®çš„æ¨¡å‹: {config.get('model', {}).get('name', 'unknown')}")
        logger.info(f"ğŸ” æ‰¹æ¬¡å¤§å°: {config.get('training', {}).get('batch_size', 'unknown')}")
        logger.info(f"ğŸ” å­¸ç¿’ç‡: {config.get('training', {}).get('learning_rate', 'unknown')}")
        logger.info(f"ğŸ” æœ€å¤§é•·åº¦: {config.get('data', {}).get('max_length', 'unknown')}")
        logger.info(f"ğŸš€ å¿«é€Ÿæ¸¬è©¦æ¨¡å¼: {config.get('training', {}).get('quick_test', False)}")
        logger.info(f"ğŸ”§ æ•¸æ“šåŠ è¼‰å™¨å·¥ä½œé€²ç¨‹: {config.get('system', {}).get('num_workers', 0)}")
        
        return config
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}")
        raise

def get_gpu_memory_info():
    """ç²å–GPUè¨˜æ†¶é«”ä¿¡æ¯"""
    if torch.cuda.is_available():
        device = torch.cuda.current_device()
        total = torch.cuda.get_device_properties(device).total_memory / 1e9
        allocated = torch.cuda.memory_allocated(device) / 1e9
        return f"{allocated:.1f}GB/{total:.1f}GB"
    return "N/A"

def setup_environment():
    """è¨­ç½®è¨“ç·´ç’°å¢ƒ"""
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸ”§ Setting up training environment...")
    
    # è¨­ç½®éš¨æ©Ÿç¨®å­
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(42)
    
    # GPUä¿¡æ¯
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        cuda_version = torch.version.cuda
        pytorch_version = torch.__version__
        
        logger.info(f"ğŸ”¥ GPU: {gpu_name}")
        logger.info(f"ğŸ”¥ CUDAç‰ˆæœ¬: {cuda_version}")
        logger.info(f"ğŸ”¥ GPUè¨˜æ†¶é«”: {gpu_memory:.2f} GB")
        logger.info(f"ğŸ PyTorchç‰ˆæœ¬: {pytorch_version}")
    else:
        logger.warning("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨CPUè¨“ç·´")

class ChineseReasoningDataProcessor:
    """ä¸­æ–‡æ¨ç†æ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self, data_path: str):
        self.data_path = data_path
        self.df = None
        self.processed_data = None
        self.logger = logging.getLogger(__name__)
        
    def load_data(self):
        """è¼‰å…¥æ•¸æ“š"""
        try:
            self.logger.info(f"ğŸ“Š Loading data from: {self.data_path}")
            
            if not os.path.exists(self.data_path):
                raise FileNotFoundError(f"æ•¸æ“šæ–‡ä»¶ä¸å­˜åœ¨: {self.data_path}")
            
            self.df = pd.read_csv(self.data_path, sep='\t')
            
            self.logger.info(f"âœ… Loaded {len(self.df)} samples")
            self.logger.info(f"ğŸ“‹ Columns: {list(self.df.columns)}")
            
            # çµ±è¨ˆä¿¡æ¯
            self.logger.info("ğŸ“ˆ Data Statistics:")
            self.logger.info(f"   - Total rows: {len(self.df)}")
            self.logger.info(f"   - Missing values: {self.df.isnull().sum().sum()}")
            
            file_size = os.path.getsize(self.data_path) / (1024 * 1024)
            self.logger.info(f"   - File size: {file_size:.2f} MB")
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def extract_reasoning_components(self, reasoning_text: str) -> Dict[str, str]:
        """æå–æ¨ç†çµ„ä»¶"""
        try:
            components = {
                "analysis": "åˆ†ææ­¥é©Ÿ",
                "key_point": "é—œéµè¦é»", 
                "conclusion": "çµè«–"
            }
            
            # ç°¡åŒ–è™•ç†ï¼šå°‡æ¨ç†æ–‡æœ¬åˆ†æ®µ
            text = str(reasoning_text).strip()
            sentences = text.split('ã€‚')
            
            if len(sentences) >= 3:
                components["analysis"] = sentences[0] + "ã€‚"
                components["key_point"] = sentences[1] + "ã€‚"
                components["conclusion"] = sentences[-1] if sentences[-1] else sentences[-2]
            else:
                components["analysis"] = text
                components["key_point"] = text
                components["conclusion"] = text
            
            return components
            
        except Exception as e:
            self.logger.warning(f"æ¨ç†çµ„ä»¶æå–å¤±æ•—: {e}")
            return {
                "analysis": str(reasoning_text),
                "key_point": str(reasoning_text),
                "conclusion": str(reasoning_text)
            }
    
    def create_grpo_pairs(self, question: str, options: str, correct_answer: str, 
                         reasoning_components: Dict[str, str]) -> List[Dict]:
        """å‰µå»ºGRPOåå¥½å°"""
        pairs = []
        
        try:
            # åŸºæœ¬æç¤º
            prompt = f"å•é¡Œï¼š{question}\né¸é …ï¼š\n{options}\nè«‹é¸æ“‡æ­£ç¢ºç­”æ¡ˆä¸¦èªªæ˜ç†ç”±ã€‚"
            
            # æ­£ç¢ºå›ç­”ï¼ˆchosenï¼‰
            chosen = f"ç­”æ¡ˆï¼š{correct_answer}\nç†ç”±ï¼š{reasoning_components['analysis']}"
            
            # å‰µå»ºéŒ¯èª¤å›ç­”ï¼ˆrejectedï¼‰
            wrong_answers = ['A', 'B', 'C', 'D']
            if correct_answer in wrong_answers:
                wrong_answers.remove(correct_answer)
            
            for wrong_answer in wrong_answers[:2]:  # åªå–å‰2å€‹éŒ¯èª¤ç­”æ¡ˆ
                rejected = f"ç­”æ¡ˆï¼š{wrong_answer}\nç†ç”±ï¼šé€™å€‹é¸é …ä¸æ­£ç¢ºã€‚"
                
                pairs.append({
                    "prompt": prompt,
                    "chosen": chosen,
                    "rejected": rejected
                })
            
            return pairs
            
        except Exception as e:
            self.logger.warning(f"å‰µå»ºåå¥½å°å¤±æ•—: {e}")
            return []
    
    def process_data_for_grpo(self) -> List[Dict]:
        """è™•ç†æ•¸æ“šç”¨æ–¼GRPOè¨“ç·´"""
        if self.df is None:
            self.load_data()
        
        self.logger.info("ğŸ”„ Processing data for GRPO training...")
        
        all_pairs = []
        failed_count = 0
        
        for idx, row in tqdm(self.df.iterrows(), total=len(self.df), desc="Processing data"):
            try:
                question = str(row['question']).strip()
                options = f"A. {row['option_A']}\nB. {row['option_B']}\nC. {row['option_C']}\nD. {row['option_D']}"
                correct_answer = str(row['correct_answer']).strip()
                
                # æå–æ¨ç†çµ„ä»¶
                reasoning_components = self.extract_reasoning_components(str(row['reasoning_answer']))
                
                # å‰µå»ºåå¥½å°
                pairs = self.create_grpo_pairs(question, options, correct_answer, reasoning_components)
                all_pairs.extend(pairs)
                
                # é€²åº¦å ±å‘Š
                if (idx + 1) % 1000 == 0:
                    self.logger.info(f"ğŸ“Š Processed {idx + 1}/{len(self.df)} rows, generated {len(all_pairs)} pairs")
                
            except Exception as e:
                self.logger.warning(f"Error processing row {idx}: {e}")
                failed_count += 1
                continue
        
        self.logger.info("âœ… Data processing completed!")
        self.logger.info("ğŸ“Š Statistics:")
        self.logger.info(f"   - Total samples processed: {len(self.df)}")
        self.logger.info(f"   - Failed rows: {failed_count}")
        self.logger.info(f"   - Generated preference pairs: {len(all_pairs)}")
        self.logger.info(f"   - Average pairs per sample: {len(all_pairs)/len(self.df):.2f}")
        
        self.processed_data = all_pairs
        return all_pairs

class QuickTestDataProcessor(ChineseReasoningDataProcessor):
    """æ”¯æŒå¿«é€Ÿæ¸¬è©¦çš„æ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self, data_path: str, quick_test: bool = False, sample_ratio: float = 0.5):
        super().__init__(data_path)
        self.quick_test = quick_test
        self.sample_ratio = sample_ratio
    
    def process_data_for_grpo(self) -> List[Dict]:
        """è™•ç†æ•¸æ“šç”¨æ–¼GRPOè¨“ç·´ - æ”¯æŒå¿«é€Ÿæ¸¬è©¦"""
        if self.df is None:
            self.load_data()
        
        # å¿«é€Ÿæ¸¬è©¦æ¨¡å¼
        if self.quick_test:
            original_size = len(self.df)
            sample_size = max(1, int(original_size * self.sample_ratio))
            self.df = self.df.sample(n=sample_size, random_state=42).reset_index(drop=True)
            self.logger.info(f"ğŸš€ Quick test mode: using {sample_size}/{original_size} samples ({self.sample_ratio*100:.1f}%)")
        
        self.logger.info("ğŸ”„ Processing data for GRPO training...")
        
        all_pairs = []
        failed_count = 0
        
        for idx, row in tqdm(self.df.iterrows(), total=len(self.df), desc="Processing data"):
            try:
                question = str(row['question']).strip()
                options = f"A. {row['option_A']}\nB. {row['option_B']}\nC. {row['option_C']}\nD. {row['option_D']}"
                correct_answer = str(row['correct_answer']).strip()
                
                # ç°¡åŒ–æ¨ç†è™•ç†
                reasoning_text = str(row['reasoning_answer'])
                # ç§»é™¤XMLæ¨™ç±¤ä¸¦æˆªçŸ­
                clean_reasoning = re.sub(r'<[^>]+>', '', reasoning_text)
                clean_reasoning = ' '.join(clean_reasoning.split())[:300] + "..."
                
                reasoning_components = {
                    "analysis": clean_reasoning,
                    "key_point": "åŸºæ–¼åˆ†æ",
                    "conclusion": "å¾—å‡ºç­”æ¡ˆ"
                }
                
                # å‰µå»ºåå¥½å° - åªå‰µå»º1å€‹ï¼Œæ¸›å°‘æ•¸æ“šé‡
                pairs = self.create_simplified_grpo_pairs(question, options, correct_answer, reasoning_components)
                all_pairs.extend(pairs)
                
            except Exception as e:
                self.logger.warning(f"Error processing row {idx}: {e}")
                failed_count += 1
                continue
        
        self.logger.info("âœ… Data processing completed!")
        self.logger.info("ğŸ“Š Statistics:")
        self.logger.info(f"   - Total samples processed: {len(self.df)}")
        self.logger.info(f"   - Failed rows: {failed_count}")
        self.logger.info(f"   - Generated preference pairs: {len(all_pairs)}")
        
        self.processed_data = all_pairs
        return all_pairs
    
    def create_simplified_grpo_pairs(self, question: str, options: str, correct_answer: str, reasoning_components: Dict[str, str]) -> List[Dict]:
        """å‰µå»ºç°¡åŒ–çš„GRPOåå¥½å°"""
        pairs = []
        
        try:
            # ç°¡åŒ–çš„æç¤ºæ ¼å¼
            prompt = f"Question: {question}\nOptions:\n{options}\nAnswer:"
            
            # æ­£ç¢ºå›ç­”ï¼ˆchosenï¼‰
            chosen = f"{correct_answer}\nReasoning: {reasoning_components['analysis']}"
            
            # éŒ¯èª¤å›ç­”ï¼ˆrejectedï¼‰ - åªå‰µå»º1å€‹
            wrong_answers = ['A', 'B', 'C', 'D']
            if correct_answer in wrong_answers:
                wrong_answers.remove(correct_answer)
            
            wrong_answer = wrong_answers[0]
            rejected = f"{wrong_answer}\nReasoning: This option is incorrect."
            
            pairs.append({
                "prompt": prompt,
                "chosen": chosen,
                "rejected": rejected
            })
            
            return pairs
            
        except Exception as e:
            self.logger.warning(f"å‰µå»ºåå¥½å°å¤±æ•—: {e}")
            return []

class ChineseLLMSetup:
    """ä¸­æ–‡å¤§èªè¨€æ¨¡å‹è¨­ç½®é¡"""
    
    def __init__(self, model_name: str, use_4bit: bool = True):
        self.model_name = model_name
        self.use_4bit = use_4bit
        self.model_id = CHINESE_MODELS.get(model_name, model_name)
        self.model = None
        self.tokenizer = None
        self.logger = logging.getLogger(__name__)
        
        self.logger.info(f"ğŸ¤– åˆå§‹åŒ–æ¨¡å‹è¨­ç½®: {model_name}")
        self.logger.info(f"ğŸ” æ¨¡å‹ID: {self.model_id}")
        self.logger.info(f"ğŸ”§ ä½¿ç”¨4bité‡åŒ–: {use_4bit}")
    
    def setup_quantization(self):
        """è¨­ç½®é‡åŒ–é…ç½®"""
        if not self.use_4bit:
            return None
            
        quantization_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_compute_dtype=torch.float16,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4"
        )
        
        self.logger.info("âœ… 4bité‡åŒ–é…ç½®å·²è¨­ç½®")
        return quantization_config
    
    def load_model_and_tokenizer(self):
        """è¼‰å…¥æ¨¡å‹å’Œtokenizer"""
        try:
            self.logger.info("ğŸ“ Loading tokenizer...")
            
            # è¼‰å…¥tokenizer
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_id,
                trust_remote_code=True
            )
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self.logger.info("âœ… Tokenizer loaded successfully!")
            
            # è¼‰å…¥æ¨¡å‹
            self.logger.info("ğŸ§  Loading model...")
            quantization_config = self.setup_quantization()
            
            try:
                self.model = AutoModelForCausalLM.from_pretrained(
                    self.model_id,
                    quantization_config=quantization_config,
                    device_map="auto",
                    trust_remote_code=True,
                    torch_dtype=torch.float16,
                    attn_implementation="flash_attention_2"
                )
                self.logger.info("âœ… Flash Attention 2 å·²å•Ÿç”¨")
            except Exception as e:
                self.logger.warning(f"Flash attention failed, falling back: {e}")
                self.model = AutoModelForCausalLM.from_pretrained(
                    self.model_id,
                    quantization_config=quantization_config,
                    device_map="auto",
                    trust_remote_code=True,
                    torch_dtype=torch.float16
                )
            
            self.logger.info("âœ… Model loaded successfully!")
            
            # é¡¯ç¤ºè¨˜æ†¶é«”ä½¿ç”¨
            if torch.cuda.is_available():
                memory_info = get_gpu_memory_info()
                self.logger.info(f"ğŸ”¥ GPUè¨˜æ†¶é«”ä½¿ç”¨: {memory_info}")
            
            return self.model, self.tokenizer
            
        except Exception as e:
            self.logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def setup_lora(self, config: Dict):
        """è¨­ç½®LoRAé…ç½®"""
        try:
            self.logger.info("ğŸ”§ Setting up LoRA configuration...")
            
            # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡target_modules
            if "qwen" in self.model_id.lower():
                target_modules = ["q_proj", "k_proj", "v_proj", "o_proj"]
            elif "chatglm" in self.model_id.lower():
                target_modules = ["query_key_value", "dense"]
            else:
                target_modules = ["q_proj", "v_proj"]
            
            lora_config = LoraConfig(
                r=config['lora']['r'],
                lora_alpha=config['lora']['lora_alpha'],
                target_modules=target_modules,
                lora_dropout=config['lora']['lora_dropout'],
                bias=config['lora']['bias'],
                task_type="CAUSAL_LM"
            )
            
            self.model = get_peft_model(self.model, lora_config)
            
            # é¡¯ç¤ºå¯è¨“ç·´åƒæ•¸
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            all_params = sum(p.numel() for p in self.model.parameters())
            
            self.logger.info(f"ğŸ“Š Trainable parameters: {trainable_params:,}")
            self.logger.info(f"ğŸ“Š All parameters: {all_params:,}")
            self.logger.info(f"ğŸ“Š Trainable ratio: {100 * trainable_params / all_params:.2f}%")
            
            return self.model
            
        except Exception as e:
            self.logger.error(f"âŒ LoRAè¨­ç½®å¤±æ•—: {e}")
            raise

def setup_wandb(config: Dict):
    """è¨­ç½®Weights & Biasesè¨˜éŒ„"""
    logger = logging.getLogger(__name__)
    
    if config['system']['use_wandb']:
        try:
            logger.info("ğŸ“Š Setting up WandB...")
            
            run_name = f"grpo-training-{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            wandb.init(
                project=config['system']['wandb_project'],
                name=run_name,
                config=config
            )
            logger.info("âœ… WandB initialized successfully")
        except Exception as e:
            logger.warning(f"Failed to initialize WandB: {e}")

# å…¨å±€å®šç¾©reward function ä»¥æ”¯æŒå¤šé€²ç¨‹
def global_reward_function(prompts, completions, **kwargs):
    """Global GRPO reward function with correct signature"""
    import torch
    
    rewards = []
    for prompt, completion in zip(prompts, completions):
        # ç°¡å–®çå‹µé‚è¼¯
        if "Answer:" in completion or "ç­”æ¡ˆï¼š" in completion:
            reward = 1.0
        else:
            reward = 0.5
        rewards.append(reward)
    
    return torch.tensor(rewards, dtype=torch.float32)

def main():
    """ä¸»è¨“ç·´å‡½æ•¸ - ä¿®å¾©ç‰ˆæœ¬"""
    
    print("="*60)
    print("ğŸš€ FIXED GRPO Training for Chinese LLM Reasoning (v2)")
    print("="*60)
    
    # è¨­ç½®æ—¥èªŒ
    logger, main_log_file, progress_log_file, error_log_file = setup_logging()
    
    try:
        logger.info("ğŸ¯ Starting FIXED GRPO training session")
        logger.info(f"ğŸ“… Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # è¼‰å…¥é…ç½®ï¼ˆä½¿ç”¨ä¿®å¾©å¾Œçš„è¼‰å…¥å™¨ï¼‰
        logger.info("ğŸ“– Loading configuration...")
        config = load_config('/home/ubuntu/DL/kaggle#3/configs/training_config_fixed.yaml')
        
        # è¨­ç½®ç’°å¢ƒ
        logger.info("ğŸ”§ Setting up environment...")
        setup_environment()
        
        # è¨­ç½®WandB
        setup_wandb(config)
        
        logger.info("="*40)
        logger.info("ğŸ“Š STEP 1: Processing training data...")
        
        # æ­¥é©Ÿ1: ä½¿ç”¨å¿«é€Ÿæ¸¬è©¦æ•¸æ“šè™•ç†å™¨
        data_processor = QuickTestDataProcessor(
            data_path=config['data']['train_path'],
            quick_test=config['training'].get('quick_test', True),
            sample_ratio=config['training'].get('sample_ratio', 0.5)
        )
        preference_pairs = data_processor.process_data_for_grpo()
        
        if not preference_pairs:
            raise ValueError("æ²’æœ‰ç”Ÿæˆä»»ä½•è¨“ç·´æ•¸æ“šå°")
        
        logger.info(f"ğŸ“Š Generated {len(preference_pairs)} preference pairs for quick test")
        
        logger.info("="*40)
        logger.info("ğŸ¤– STEP 2: Setting up model...")
        
        # æ­¥é©Ÿ2: è¨­ç½®æ¨¡å‹
        model_setup = ChineseLLMSetup(
            model_name=config['model']['name'],
            use_4bit=config['model']['use_4bit_quantization']
        )
        model, tokenizer = model_setup.load_model_and_tokenizer()
        model = model_setup.setup_lora(config)
        
        logger.info("="*40)
        logger.info("ğŸ“ STEP 3: Preparing dataset...")
        
        # æ­¥é©Ÿ3: æº–å‚™æ•¸æ“šé›† - æ”¹é€²ç‰ˆtokenization
        def improved_tokenize_function(examples):
            """æ”¹é€²çš„tokenizeå‡½æ•¸ï¼Œæ­£ç¢ºè™•ç†GRPOæ ¼å¼"""
            max_length = config['data']['max_length']
            
            # ç¢ºä¿æ‰€æœ‰è¼¸å…¥éƒ½æ˜¯å­—ç¬¦ä¸²
            prompts = [str(p) for p in examples["prompt"]]
            chosen = [str(c) for c in examples["chosen"]]
            rejected = [str(r) for r in examples["rejected"]]
            
            # Tokenize prompts
            prompt_encodings = tokenizer(
                prompts, 
                max_length=max_length,
                truncation=True,
                padding=False
            )
            
            # Tokenize chosen responses
            chosen_encodings = tokenizer(
                chosen,
                max_length=max_length,
                truncation=True,
                padding=False
            )
            
            # Tokenize rejected responses
            rejected_encodings = tokenizer(
                rejected,
                max_length=max_length,
                truncation=True,
                padding=False
            )
            
            return {
                "prompt": prompts,
                "chosen": chosen, 
                "rejected": rejected,
                "input_ids": prompt_encodings["input_ids"],
                "attention_mask": prompt_encodings["attention_mask"],
                "chosen_input_ids": chosen_encodings["input_ids"],
                "chosen_attention_mask": chosen_encodings["attention_mask"],
                "rejected_input_ids": rejected_encodings["input_ids"],
                "rejected_attention_mask": rejected_encodings["attention_mask"]
            }
        
        # å‰µå»ºæ•¸æ“šé›†
        logger.info(f"ğŸ”„ Creating dataset from {len(preference_pairs)} preference pairs...")
        dataset = Dataset.from_list(preference_pairs)
        
        # æ”¹é€²çš„è™•ç†
        dataset = dataset.map(improved_tokenize_function, batched=True)
        
        # åˆ†å‰²æ•¸æ“šé›†
        split_ratio = config['data']['train_test_split']
        if split_ratio > 0 and len(dataset) > 10:  # åªæœ‰è¶³å¤ æ•¸æ“šæ‰åˆ†å‰²
            dataset = dataset.train_test_split(test_size=split_ratio)
            train_dataset = dataset['train']
            eval_dataset = dataset['test']
            logger.info(f"ğŸ“Š Train samples: {len(train_dataset)}")
            logger.info(f"ğŸ“Š Eval samples: {len(eval_dataset)}")
        else:
            train_dataset = dataset
            eval_dataset = None
            logger.info(f"ğŸ“Š Train samples: {len(train_dataset)}")
        
        logger.info("="*40)
        logger.info("ğŸ¯ STEP 4: Setting up GRPO trainer...")
        
        # æ­¥é©Ÿ4: è¨­ç½®GRPOè¨“ç·´å™¨
        os.makedirs(config['training']['output_dir'], exist_ok=True)
        
        # ç¢ºä¿å­¸ç¿’ç‡æ˜¯æµ®é»æ•¸
        learning_rate = config['training']['learning_rate']
        if isinstance(learning_rate, str):
            learning_rate = float(learning_rate)
            logger.info(f"ğŸ”§ Converted learning_rate from str to float: {learning_rate}")
        
        # GRPOé…ç½® - ã€é—œéµä¿®å¾©ã€‘è¨­ç½® num_workers ç‚º 0
        grpo_config = GRPOConfig(
            output_dir=str(config['training']['output_dir']),
            per_device_train_batch_size=int(config['training']['batch_size']),
            per_device_eval_batch_size=int(config['training']['batch_size']),
            gradient_accumulation_steps=int(config['training']['gradient_accumulation_steps']),
            num_train_epochs=int(config['training']['num_epochs']),
            learning_rate=float(learning_rate),  # ç¢ºä¿æ˜¯æµ®é»æ•¸
            warmup_steps=int(config['training']['warmup_steps']),
            logging_steps=int(config['training']['logging_steps']),
            save_steps=int(config['training']['save_steps']),
            eval_steps=int(config['training']['eval_steps']),
            bf16=bool(config['system']['bf16']),
            gradient_checkpointing=bool(config['system']['gradient_checkpointing']),
            dataloader_num_workers=0,  # ã€é—œéµä¿®å¾©ã€‘å¼·åˆ¶è¨­ç‚º0é¿å…pickleå•é¡Œ
            remove_unused_columns=False,
            report_to="wandb" if config['system']['use_wandb'] else None
        )
        
        logger.info("âœ… GRPO configuration created successfully")
        logger.info(f"ğŸ” Learning rate type: {type(grpo_config.learning_rate)}, value: {grpo_config.learning_rate}")
        logger.info(f"ğŸ”§ DataLoader workers: {grpo_config.dataloader_num_workers} (fixed to avoid pickle error)")
        
        # å‰µå»ºè¨“ç·´å™¨ - ä½¿ç”¨å…¨å±€reward function
        trainer = GRPOTrainer(
            model=model,
            args=grpo_config,
            train_dataset=train_dataset,
            eval_dataset=eval_dataset,
            processing_class=tokenizer,
            reward_funcs=[global_reward_function],  # ä½¿ç”¨å…¨å±€å‡½æ•¸
        )
        logger.info("âœ… GRPO trainer created successfully")
        
        logger.info("="*40)
        logger.info("ğŸš€ STEP 5: Starting training...")
        
        # æ­¥é©Ÿ5: é–‹å§‹è¨“ç·´
        logger.info(f"ğŸ”¥ GPUè¨˜æ†¶é«”: {get_gpu_memory_info()}")
        logger.info("ğŸ¯ Starting QUICK TEST GRPO training...")
        
        # é–‹å§‹è¨“ç·´
        trainer.train()
        
        logger.info("="*40)
        logger.info("ğŸ’¾ STEP 6: Saving model...")
        
        # æ­¥é©Ÿ6: ä¿å­˜æ¨¡å‹
        model_save_path = os.path.join(config['training']['output_dir'], "grpo_reasoning_model_50percent")
        trainer.save_model(model_save_path)
        tokenizer.save_pretrained(model_save_path)
        
        logger.info(f"âœ… Model saved to: {model_save_path}")
        
        # ç”Ÿæˆè©•ä¼°æ¨£æœ¬
        logger.info("ğŸ§ª Generating evaluation sample...")
        test_sample = preference_pairs[0]
        
        inputs = tokenizer(test_sample["prompt"], return_tensors="pt")
        if torch.cuda.is_available():
            inputs = {k: v.cuda() for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=100,
                do_sample=True,
                temperature=0.7,
                pad_token_id=tokenizer.eos_token_id
            )
        
        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        evaluation_result = {
            "prompt": test_sample["prompt"],
            "chosen": test_sample["chosen"],
            "rejected": test_sample["rejected"],
            "generated": generated_text
        }
        
        with open(f"{config['training']['output_dir']}/evaluation_sample.json", 'w', encoding='utf-8') as f:
            json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
        
        print("="*60)
        print("ğŸ‰ QUICK TEST GRPO Training Completed Successfully!")
        print(f"ğŸ“ Model saved to: {model_save_path}")
        print(f"ğŸ“Š Evaluation sample: {config['training']['output_dir']}/evaluation_sample_20percent.json")
        print("ğŸš€ Ready for full training if results look good!")
        print("ğŸ’¡ Key fix: Set dataloader_num_workers=0 to avoid pickle errors")
        print("="*60)
        
    except Exception as e:
        logger.error(f"âŒ Training failed: {e}")
        logger.error("å®Œæ•´éŒ¯èª¤ä¿¡æ¯:")
        logger.error(traceback.format_exc())
        raise
    
    finally:
        # æ¸…ç†è³‡æº
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        if 'config' in locals() and config['system']['use_wandb']:
            wandb.finish()
        
        logger.info(f"ğŸ“ Main log file: {main_log_file}")
        logger.info(f"ğŸ“ˆ Progress log file: {progress_log_file}")
        logger.info(f"âŒ Error log file: {error_log_file}")
        logger.info("ğŸ’¾ Saving final log summary...")

if __name__ == "__main__":
    main()
