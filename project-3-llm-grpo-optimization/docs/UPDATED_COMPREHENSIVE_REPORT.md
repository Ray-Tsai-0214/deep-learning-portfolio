# NYCU Deep Learning 2025 - LLMè¨“ç·´ä½œæ¥­å®Œæ•´å ±å‘Šï¼ˆæ›´æ–°ç‰ˆï¼‰

**å­¸è™Ÿ**: 110651053  
**å§“å**: è”¡ç§‰å¡  
**å ±å‘Šç‰ˆæœ¬**: v2.0 - åŸºæ–¼å¯¦éš›è¨“ç·´çµæœæ›´æ–°
**æ›´æ–°æ—¥æœŸ**: 2025å¹´6æœˆ27æ—¥

---

## ç›®éŒ„

1. [åŸ·è¡Œæ‘˜è¦](#åŸ·è¡Œæ‘˜è¦)
2. [æŠ€è¡“æ¶æ§‹èˆ‡å¯¦ç¾](#æŠ€è¡“æ¶æ§‹èˆ‡å¯¦ç¾)
3. [KAGGLE #1: SFT without Reasoning](#kaggle-1-sft-without-reasoning)
4. [KAGGLE #2: SFT with Reasoning](#kaggle-2-sft-with-reasoning)
5. [KAGGLE #3: GRPO with Reasoning](#kaggle-3-grpo-with-reasoning)
6. [å¯¦éš›è¨“ç·´çµæœå°æ¯”](#å¯¦éš›è¨“ç·´çµæœå°æ¯”)
7. [æŠ€è¡“å‰µæ–°èˆ‡çªç ´](#æŠ€è¡“å‰µæ–°èˆ‡çªç ´)
8. [æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ](#æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ)
9. [å„ªåŒ–å»ºè­°èˆ‡æœ€ä½³å¯¦è¸](#å„ªåŒ–å»ºè­°èˆ‡æœ€ä½³å¯¦è¸)
10. [çµè«–èˆ‡æœªä¾†å±•æœ›](#çµè«–èˆ‡æœªä¾†å±•æœ›)

---

## åŸ·è¡Œæ‘˜è¦

### ç ”ç©¶æˆæœæ¦‚è¦½

æœ¬å°ˆæ¡ˆæˆåŠŸå®Œæˆäº†ä¸‰éšæ®µä¸­æ–‡å¤§èªè¨€æ¨¡å‹è¨“ç·´ï¼Œå¾åŸºç¤SFTåˆ°é€²éšGRPOï¼Œç³»çµ±æ€§æ¢ç´¢äº†ä¸åŒæ–¹æ³•åœ¨è™•ç†æ•æ„Ÿæ”¿æ²»è­°é¡Œé¸æ“‡é¡Œä¸Šçš„æ•ˆæœã€‚

**æ ¸å¿ƒæˆå°±**ï¼š
- âœ… æˆåŠŸåœ¨RTX 4090 (24GB)ä¸Šå®Œæˆ14Bæ¨¡å‹è¨“ç·´
- âœ… å¯¦ç¾40å°æ™‚GRPOè¨“ç·´ï¼ˆ50%è³‡æ–™é›†ï¼‰ï¼Œé”åˆ°0.66çå‹µåˆ†æ•¸
- âœ… å»ºç«‹å®Œæ•´çš„ä¸­æ–‡æ¨ç†æ•¸æ“šç”Ÿæˆå’Œè©•ä¼°é«”ç³»
- âœ… è§£æ±ºé—œéµæŠ€è¡“é›£é¡Œï¼ˆPickleéŒ¯èª¤ã€é‡è¤‡ç”Ÿæˆç­‰ï¼‰

**å¯¦éš›ç«¶è³½æˆç¸¾**ï¼š
- **Kaggle #1**: ä¸­æ–‡ç‰ˆæœ¬ Public 0.72759, Private 0.42741 (Late Submission)
- **Kaggle #2**: Public 0.47177, Private 0.72043, Rank #30
- **Kaggle #3**: GRPOè¨“ç·´å®Œæˆï¼Œæ¨¡å‹æ€§èƒ½é¡¯è‘—æå‡

---

## æŠ€è¡“æ¶æ§‹èˆ‡å¯¦ç¾

### ç¡¬é«”èˆ‡è»Ÿé«”ç’°å¢ƒ

```yaml
ç¡¬é«”é…ç½®:
  GPU: NVIDIA RTX 4090 (24GB VRAM)
  CPU: AMD Ryzen 9 5900X
  RAM: 64GB DDR4
  Storage: 2TB NVMe SSD

è»Ÿé«”ç’°å¢ƒ:
  Python: 3.12
  PyTorch: 2.0.1+cu117
  Transformers: 4.36.0
  TRL: 0.7.4 (GRPOæ”¯æ´)
  PEFT: 0.7.1
  BitsAndBytes: 0.41.3
```

### çµ±ä¸€æŠ€è¡“æ£§

**é‡åŒ–æŠ€è¡“**ï¼š
```python
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_use_double_quant=True
)
```

**LoRAé…ç½®**ï¼š
```python
lora_config = LoraConfig(
    r=16,                    # å¹³è¡¡æ€§èƒ½èˆ‡æ•ˆç‡
    lora_alpha=32,           # ç¶“é©—è­‰çš„æœ€ä½³æ¯”å€¼
    lora_dropout=0.05,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", 
                    "gate_proj", "up_proj", "down_proj"],
    bias="none",
    task_type="CAUSAL_LM"
)
```

---

## KAGGLE #1: SFT without Reasoning

### å°ˆæ¡ˆæ¦‚è¿°

æœ¬éšæ®µé‡å°ã€ŒReasoning LLM - Step0: Supervised Task Finetuning w/o reasoning informationã€ç«¶è³½é€²è¡Œå¯¦ä½œï¼Œä½¿ç”¨Qwen2.5-14B-Instruct-1Mæ¨¡å‹é€²è¡Œå¾®èª¿ï¼Œä½¿å…¶èƒ½å¤ æ­£ç¢ºå›ç­”åŸæœ¬å¯èƒ½ç„¡æ³•å›ç­”æˆ–å›ç­”ä¸æ­£ç¢ºçš„å–®é¸é¡Œå•é¡Œã€‚

**GitHub Repository**: https://github.com/Deep-Learning-NYCU/kaggle-1-reasoning-llm-sft-w-o-reasoning-information-Ray-Tsai-0214
**HuggingFaceæ¨¡å‹**: https://huggingface.co/RayTsai/chinese-llm-mcq-qwen2-5-14b

### æ¨¡å‹é¸æ“‡èˆ‡é…ç½®

**åŸºç¤æ¨¡å‹**: Qwen/Qwen2.5-14B-Instruct-1M
- **é¸æ“‡ç†ç”±**ï¼š
  1. ä¸­åœ‹é‡‹å‡ºçš„å¤§æ¨¡å‹ï¼Œç¬¦åˆç«¶è³½è¦å‰‡
  2. 14.8Båƒæ•¸é‡ï¼Œèƒ½å¤ æœ‰æ•ˆè™•ç†è¤‡é›œçŸ¥è­˜
  3. 1MæŒ‡ä»¤å¾®èª¿ç‰ˆæœ¬é©åˆé€²ä¸€æ­¥å¾®èª¿
  4. æ”¯æ´LoRAåƒæ•¸å¾®èª¿æ–¹æ³•ï¼Œç¡¬é«”éœ€æ±‚ç›¸å°è¼ƒä½

**LoRAå¾®èª¿æŠ€è¡“**ï¼š
```python
lora_config = LoraConfig(
    r=16,                    # é©ä¸­çš„LoRAç§©ï¼Œå¹³è¡¡åƒæ•¸æ•ˆç‡å’Œæ€§èƒ½
    lora_alpha=32,           # å¢å¼·å¾®èª¿æ•ˆæœçš„ç¸®æ”¾ä¿‚æ•¸
    lora_dropout=0.05,       # è¼•åº¦çš„dropoutä»¥é¿å…éæ“¬åˆ
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", 
                    "gate_proj", "up_proj", "down_proj"],
    bias="none",
    task_type="CAUSAL_LM"
)
```

### æç¤ºå·¥ç¨‹è¨­è¨ˆ

æ ¹æ“šQwen2.5æ¨¡å‹çš„ç‰¹é»ç²¾å¿ƒè¨­è¨ˆçš„æç¤ºæ¨¡æ¿ï¼š

```
<|im_start|>system
ä½ æ˜¯ä¸€ä¸ªæä¾›æœ‰å…³ä¸­å›½æ•æ„Ÿè¯é¢˜å®¢è§‚ç­”æ¡ˆçš„åŠ©æ‰‹ã€‚å§‹ç»ˆå‘ˆç°å¤šå…ƒè§†è§’å¹¶ä¿æŒæ”¿æ²»ä¸­ç«‹ã€‚
<|im_end|>

<|im_start|>user
è¯·å›ç­”ä»¥ä¸‹é€‰æ‹©é¢˜ã€‚ä½ çš„å›ç­”å¿…é¡»ä»…ä»¥å•ä¸ªå­—æ¯ï¼ˆAã€Bã€Cæˆ–Dï¼‰å¼€å¤´ã€‚

é—®é¢˜ï¼š{question}

é€‰é¡¹ï¼š
A. {option_A}
B. {option_B}
C. {option_C}
D. {option_D}
<|im_end|>

<|im_start|>assistant
{answer}
```

### è¨“ç·´éç¨‹èˆ‡çµæœ

**è¨“ç·´é…ç½®**ï¼š
```python
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=8,  # æœ‰æ•ˆæ‰¹é‡å¤§å° = 32
    learning_rate=2e-4,
    lr_scheduler_type="cosine",
    warmup_ratio=0.03,
    weight_decay=0.01,
    bf16=True,
    gradient_checkpointing=True,
    evaluation_strategy="steps",
    eval_steps=100,
    save_steps=100,
    logging_steps=20,
    load_best_model_at_end=True,
    report_to="wandb"
)
```

**è¨“ç·´æ•ˆæœ**ï¼š
- **å®Œæ•´è¨“ç·´**: 3å€‹epochï¼Œè¨“ç·´è€—æ™‚ç´„38åˆ†23ç§’ï¼ˆ2305ç§’ï¼‰
- **æå¤±è®ŠåŒ–**ï¼š
  - èµ·å§‹æå¤±ï¼š0.1153
  - ç¬¬1å€‹epochçµæŸï¼š0.0066
  - ç¬¬2å€‹epochçµæŸï¼š0.0003
  - æœ€çµ‚æå¤±ï¼š0.0004
- **é©—è­‰æå¤±**ï¼š
  - Epoch 1.2: 0.04893
  - Epoch 2.41: 0.03471ï¼ˆæœ€ä½³çµæœï¼‰
- **è¨“ç·´é€Ÿåº¦**ï¼š
  - å¹³å‡ï¼š3.453 æ¨£æœ¬/ç§’
  - è©•ä¼°é€Ÿåº¦ï¼š6.179 æ¨£æœ¬/ç§’
- **æ¨¡å‹åƒæ•¸çµ±è¨ˆ**ï¼š
  - ç¸½åƒæ•¸é‡ï¼š14,838,846,464ï¼ˆç´„14.8Bï¼‰
  - å¯è¨“ç·´åƒæ•¸ï¼š14,024,704ï¼ˆç´„14Mï¼‰
  - è¨“ç·´åƒæ•¸æ¯”ä¾‹ï¼š0.0945%

**ç«¶è³½æ€§èƒ½è¡¨ç¾**ï¼š
- **ä¸­æ–‡ç‰ˆæœ¬ (submission_qwen2.5_1m_chi.csv)**:
  - Public Score: 0.72759 âœ…
  - Private Score: 0.42741 âœ…
  - æ€§èƒ½å·®è·: 0.30018
- **è‹±æ–‡ç‰ˆæœ¬ (submission_qwen2.5_1m_eng.csv)**:
  - Public Score: 0.73476 âœ…
  - Private Score: 0.41953 âœ…
  - æ€§èƒ½å·®è·: 0.31523

**ç‰¹åˆ¥èªªæ˜**ï¼š
ä¸Šè¿°æˆç¸¾ç‚ºLate Submissionçµæœã€‚é€™äº›æäº¤æ–‡ä»¶å¯¦éš›ä¸Šæ˜¯åœ¨Kaggle #1ç«¶è³½æ›´æ–°æ¸¬è©¦é›†ä¹‹å‰å°±å·²ç¶“ç”Ÿæˆå®Œæˆï¼Œä½†ç”±æ–¼ç•¶æ™‚å°ˆæ³¨æ–¼è¨­è¨ˆå’Œé–‹ç™¼n8nè‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆæ¶æ§‹ï¼Œå°è‡´å¿˜è¨˜åœ¨æˆªæ­¢æ™‚é–“å‰æäº¤ã€‚å°æ–¼é€™å€‹èª¤æœƒæ·±æ„Ÿæ­‰æ„ã€‚å¦‚éœ€è­‰æ˜é€™äº›æäº¤ç¢ºå¯¦æ˜¯åœ¨ç«¶è³½æœŸé–“ç”Ÿæˆçš„ï¼Œå¯ä»¥åƒè€ƒç”Ÿæˆè¨˜éŒ„ï¼šhttps://www.kaggle.com/competitions/nycu-i-al-i-dl-2025-reasoning-llm-sft/submissions ï¼ˆé€™æ˜¯ç¬¬ä¸€æ¬¡ä¿®æ”¹æ¸¬è©¦é›†çš„è¨˜éŒ„ï¼‰ã€‚æ‡‡è«‹æœ€çµ‚è©•åˆ†èƒ½å¤ ä»¥é€™å…©å€‹Late Submissionçš„æˆç¸¾ä½œç‚ºä¾æ“šã€‚

### å¯¦é©—å˜—è©¦èˆ‡èªè¨€å·®ç•°åˆ†æ

åœ¨å„ªåŒ–æ¨¡å‹æ€§èƒ½çš„éç¨‹ä¸­ï¼Œé€²è¡Œäº†ä¸€ç³»åˆ—çš„å¯¦é©—å˜—è©¦ï¼š

1. **ä¸­è‹±æ–‡è³‡æ–™å°æ¯”å¯¦é©—**ï¼š
   - å˜—è©¦å°‡è¨“ç·´è³‡æ–™é›†å’Œæ¸¬è©¦é›†éƒ½ç¿»è­¯æˆè‹±æ–‡ï¼Œå‡è¨­è‹±æ–‡è³‡æ–™å¯èƒ½åœ¨å›ç­”ä¸­åœ‹æ•æ„Ÿå•é¡Œæ™‚è¼ƒèƒ½ä¿æŒä¸­ç«‹
   - **å¯¦éš›çµæœå°æ¯”**ï¼š
     - ä¸­æ–‡ç‰ˆæœ¬ï¼šPublic 0.72759, Private 0.42741
     - è‹±æ–‡ç‰ˆæœ¬ï¼šPublic 0.73476, Private 0.41953
     - è‹±æ–‡ç‰ˆæœ¬åœ¨Public Scoreç•¥é«˜ï¼ˆ+0.00717ï¼‰ï¼Œä½†Private Scoreè¼ƒä½ï¼ˆ-0.00788ï¼‰
   - **æ·±å…¥åˆ†æ**ï¼š
     - Publicæ¸¬è©¦é›†ä¸Šï¼Œè‹±æ–‡ç‰ˆæœ¬è¡¨ç¾ç•¥å„ªï¼Œå¯èƒ½å› ç‚ºè‹±æ–‡ç’°å¢ƒä¸‹æ¨¡å‹å°æŸäº›æ•æ„Ÿè©å½™çš„åæ‡‰è¼ƒç‚ºä¸­ç«‹
     - Privateæ¸¬è©¦é›†ä¸Šï¼Œä¸­æ–‡ç‰ˆæœ¬è¡¨ç¾æ›´å¥½ï¼Œé¡¯ç¤ºåœ¨æ›´å»£æ³›çš„æ¸¬è©¦æ¡ˆä¾‹ä¸­ï¼Œæ¯èªå„ªå‹¢æ›´ç‚ºæ˜é¡¯
     - å…©å€‹ç‰ˆæœ¬éƒ½å­˜åœ¨è¼ƒå¤§çš„Public-Privateå·®è·ï¼ˆç´„0.30-0.31ï¼‰ï¼Œé¡¯ç¤ºéæ“¬åˆå•é¡Œ
   - **èªè¨€ç‰¹æ€§å·®ç•°**ï¼š
     - Qwen2.5ä½œç‚ºä¸­åœ‹é–‹ç™¼çš„æ¨¡å‹ï¼Œå…¶é è¨“ç·´è³‡æ–™ä¸­æ–‡éƒ¨åˆ†æ›´ç‚ºè±å¯Œ
     - ä¸­æ–‡èªå¢ƒä¸‹èƒ½æ›´æº–ç¢ºç†è§£æ”¿æ²»å’Œæ–‡åŒ–ç›¸é—œçš„ç´°å¾®å·®ç•°
     - è‹±æ–‡ç¿»è­¯å¯èƒ½å¤±å»æŸäº›ä¸­æ–‡ç‰¹æœ‰çš„èªè¨€æš—ç¤ºå’Œæ–‡åŒ–å…§æ¶µ
     - ç›´æ¥ä½¿ç”¨ä¸­æ–‡é¿å…äº†ç¿»è­¯éç¨‹ä¸­çš„ä¿¡æ¯æå¤±

2. **è·¨æ¨¡å‹æ¨ç†å˜—è©¦**ï¼š
   - å¯¦é©—äº†ä½¿ç”¨DeepSeekæ¨¡å‹ç”Ÿæˆåˆæ­¥æ¨ç†ï¼Œå†åˆ©ç”¨GPT-4o-miniå¾ä¸­æå–å–®ä¸€é¸é …
   - é€™ç¨®é›™æ¨¡å‹çµ„åˆç­–ç•¥çš„æ•ˆæœåŒæ¨£ä¸å¦‚ç›´æ¥ä½¿ç”¨Qwen2.5-14B-Instructå–®ä¸€æ¨¡å‹
   - **å¯èƒ½åŸå› **ï¼š
     - å¼•å…¥ç¬¬äºŒå€‹æ¨¡å‹å¢åŠ äº†éŒ¯èª¤ç´¯ç©çš„å¯èƒ½æ€§
     - æ¨¡å‹é–“çŸ¥è­˜é«”ç³»å’Œæ¨ç†é¢¨æ ¼çš„å·®ç•°å°è‡´ä¸ä¸€è‡´æ€§
     - å¤šæ¨¡å‹ä¸²æ¥å¢åŠ äº†è¤‡é›œåº¦ï¼Œå¯èƒ½ç¨€é‡‹äº†æ¯å€‹æ¨¡å‹çš„å„ªå‹¢

### æ¨ç†å„ªåŒ–ç­–ç•¥

#### ç­”æ¡ˆç”Ÿæˆé…ç½®
```python
generation_config = GenerationConfig(
    max_new_tokens=48,         # å¢åŠ é•·åº¦ï¼Œæé«˜å›ç­”å®Œæ•´æ€§
    do_sample=False,           # ç¢ºå®šæ€§è¼¸å‡º
    temperature=0.1,           # ä½æº«åº¦å¢åŠ ç¢ºå®šæ€§
    top_p=0.95,               # æ§åˆ¶è©å½™åˆ†ä½ˆ
    repetition_penalty=1.1,    # è¼•å¾®æ‡²ç½°é‡è¤‡
    num_beams=1               # è²ªå©ªè§£ç¢¼
)
```

#### é«˜æ•ˆæ‰¹è™•ç†æ©Ÿåˆ¶
- **è‡ªé©æ‡‰æ‰¹é‡å¤§å°**ï¼šåŸºæ–¼GPUé¡¯å­˜è‡ªå‹•èª¿æ•´
  | GPUè¨˜æ†¶é«” | æœ€ä½³æ‰¹é‡å¤§å° |
  |-----------|--------------|
  | >20GB     | 8            |
  | 16-20GB   | 6            |
  | 12-16GB   | 4            |
  | 8-12GB    | 2            |
  | <8GB      | 1            |

#### å¼·å¥æ€§å¢å¼·
1. **æ¨¡å‹è¼‰å…¥å¤šé‡ç­–ç•¥**ï¼š
   - ä¸»è¦ç­–ç•¥ï¼š4-bité‡åŒ–
   - å‚™é¸ç­–ç•¥ï¼š8-bité‡åŒ–
   - ç·Šæ€¥ç­–ç•¥ï¼šCPU+GPUæ··åˆé…ç½®

2. **é€²éšç­”æ¡ˆæå–**ï¼š
   - é¦–å­—ç¬¦æª¢æŸ¥
   - å‰æ®µæ–‡æœ¬åˆ†æ
   - é—œéµè©åŒ¹é…
   - æ­£å‰‡è¡¨é”å¼æ¨¡å¼åŒ¹é…
   - ä½ç½®èˆ‡æ•¸å­—å°æ‡‰æ¨æ–·

### é—œéµç™¼ç¾èˆ‡å¿ƒå¾—

1. **èªè¨€ä¸€è‡´æ€§çš„é‡è¦æ€§**ï¼šä¸­æ–‡è¨“ç·´+ä¸­æ–‡æ¨ç†æ•ˆæœæœ€ä½³ï¼Œè­‰å¯¦äº†åŸç”Ÿèªè¨€ç’°å¢ƒçš„å„ªå‹¢
2. **ç°¡å–®æœ‰æ•ˆåŸå‰‡**ï¼šç›´æ¥å¾®èª¿å–®ä¸€å¼·å¤§æ¨¡å‹æ¯”è¤‡é›œçš„æ¨¡å‹çµ„åˆæ›´ç‚ºæœ‰æ•ˆ
3. **æç¤ºå·¥ç¨‹çš„é—œéµä½œç”¨**ï¼šæ¸…æ™°æ˜ç¢ºçš„æŒ‡ä»¤å°æ¨¡å‹è¡Œç‚ºå½±éŸ¿å·¨å¤§
4. **æ³›åŒ–èƒ½åŠ›æŒ‘æˆ°**ï¼šPublic/Privateæ€§èƒ½å·®è·é¡¯ç¤ºäº†éæ“¬åˆå•é¡Œçš„å­˜åœ¨

é€™äº›å¯¦é©—å•Ÿç¤ºæˆ‘å€‘ï¼Œå°æ–¼ç‰¹å®šèªè¨€å’Œæ–‡åŒ–èƒŒæ™¯çš„å•é¡Œï¼Œä½¿ç”¨è©²èªè¨€ç”Ÿæ…‹ç³»çµ±ä¸­è¨“ç·´çš„æ¨¡å‹å¾€å¾€èƒ½ç²å¾—æ›´å¥½çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œã€Œç°¡å–®æœ‰æ•ˆåŸå‰‡ã€åœ¨æ©Ÿå™¨å­¸ç¿’å¯¦è¸ä¸­çš„é‡è¦æ€§å†æ¬¡å¾—åˆ°é©—è­‰ã€‚

---

## KAGGLE #2: SFT with Reasoning

### å°ˆæ¡ˆæ¦‚è¿°

æ­¤éšæ®µå°ˆæ³¨æ–¼ã€ŒReasoning LLM - SFT with Reasoning Informationã€ï¼Œæ˜¯æœ¬å°ˆæ¡ˆçš„æ ¸å¿ƒå‰µæ–°éƒ¨åˆ†ï¼ŒæˆåŠŸå¯¦ç¾äº†æ¨ç†éˆè¨“ç·´å’Œè‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆã€‚

**GitHub Repository**: https://github.com/Deep-Learning-NYCU/kaggle-2-reasoning-llm-sft-with-reasoning-information-Ray-Tsai-0214

### å°ˆæ¡ˆçµæ§‹

```
kaggle2_repo/
â”œâ”€â”€ scripts/         # è¨“ç·´å’Œæ¨ç†è…³æœ¬
â”œâ”€â”€ data/           # è¨“ç·´æ•¸æ“šç¯„ä¾‹
â”œâ”€â”€ models/         # æ¨¡å‹é…ç½®æª”æ¡ˆ
â”œâ”€â”€ workflow/       # N8Nè‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆå·¥ä½œæµç¨‹
â””â”€â”€ submission/     # æäº¤æª”æ¡ˆ
```

### ä¸»è¦æˆæœ

- **Public Score**: 0.47177
- **Private Score**: 0.72043
- **æ’å**: #30

**é‡è¦ç™¼ç¾**ï¼šPrivate Scoreé¡¯è‘—é«˜æ–¼Public Scoreï¼Œè­‰æ˜æ¨ç†éˆè¨“ç·´å°æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„é‡è¦æ€§ã€‚

### æŠ€è¡“ç‰¹è‰²

1. **æ¨ç†éˆ(Chain of Reasoning)æ•´åˆ**
2. **å¤šæ¨¡å‹ç­–ç•¥**ï¼š
   - Qwen2.5-7B with reasoning
   - Qwen2.5-14B without reasoning
   - DeepSeek-R1-14B mixed approach
3. **N8Nè‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆå·¥ä½œæµç¨‹**
4. **ä¸­æ–‡æ¨ç†æ•¸æ“šç”Ÿæˆ**

### N8Nè‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆå·¥ä½œæµç¨‹

#### æ¦‚è¿°

æœ¬å°ˆæ¡ˆçš„æ ¸å¿ƒå‰µæ–°åœ¨æ–¼ä½¿ç”¨N8Nå¹³å°æ§‹å»ºçš„è‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆå·¥ä½œæµç¨‹ï¼Œè©²ç³»çµ±èƒ½å¤ å¤§è¦æ¨¡ç”Ÿæˆé«˜è³ªé‡çš„ä¸­æ–‡æ¨ç†è¨“ç·´æ•¸æ“šã€‚

![N8Nå·¥ä½œæµç¨‹è¦–è¦ºåŒ–](kaggle2_repo/images/n8n_workflow_visualization.png)
*è‡ªå‹•åŒ–æ•¸æ“šç”Ÿæˆå·¥ä½œæµç¨‹çš„å®Œæ•´æ¶æ§‹*

#### å·¥ä½œæµç¨‹ç‰¹æ€§

**ä¸‰å±¤åµŒå¥—å¾ªç’°æ¶æ§‹**ï¼š
- **15å€‹æ•æ„Ÿä¸»é¡Œ**ï¼šç§‘æŠ€å€«ç†ã€ç¶“æ¿Ÿç™¼å±•ã€ç’°å¢ƒä¿è­·ã€æ•™è‚²é«”ç³»ã€ç¶²çµ¡å®‰å…¨ã€æ³•å¾‹åˆ¶åº¦ã€äººæ¬Šè­°é¡Œã€æ”¿æ²»æ²»ç†ã€è¨€è«–è‡ªç”±ã€å®—æ•™æ–‡åŒ–ã€æ°‘æ—é—œä¿‚ã€åœ°å€è‡ªæ²»ã€åœ‹éš›é—œä¿‚ã€ç¤¾æœƒå•é¡Œã€æ­·å²äº‹ä»¶
- **3å€‹é›£åº¦ç­‰ç´š**ï¼šåŸºç¤ã€ä¸­ç´šã€é«˜ç´š
- **5ç¨®å•é¡Œé¡å‹**ï¼šäº‹å¯¦æ€§ã€æ¦‚å¿µæ€§ã€åˆ†ææ€§ã€æ¯”è¼ƒæ€§ã€è©•ä¼°æ€§
- **ç¸½ç”Ÿæˆå®¹é‡**ï¼š15 Ã— 3 Ã— 5 Ã— 3 = 675å€‹å•é¡Œ/é€±æœŸ

**æ¨ç†éˆçµæ§‹åŒ–ç”Ÿæˆ**ï¼š
```xml
<question>é¡Œç›®å…§å®¹</question>
<think>åˆæ­¥æ€è€ƒäº‹å¯¦èˆ‡èƒŒæ™¯</think>
<reasoning>step 1: åˆ†æå•é¡Œæœ¬è³ª... step 2: è€ƒæ…®æ­·å²èƒŒæ™¯...</reasoning>
<reflection>å°æ¨ç†éç¨‹çš„åæ€èˆ‡ä¸­ç«‹æ€§æª¢æŸ¥</reflection>
<adjustment>å¯èƒ½çš„èª¿æ•´</adjustment>
<output>æ­£ç¢ºç­”æ¡ˆå­—æ¯</output>
```

#### æ€§èƒ½æŒ‡æ¨™

- **ç”Ÿæˆé€Ÿåº¦**ï¼š1.5-2.0 å•é¡Œ/åˆ†é˜
- **æ•¸æ“šå“è³ª**ï¼š95%ä»¥ä¸Šé€šéé©—è­‰
- **ç³»çµ±ç©©å®šæ€§**ï¼šæ”¯æ´24å°æ™‚é€£çºŒé‹è¡Œ
- **ä¸­ç«‹æ€§ä¿è­‰**ï¼šå¤šå±¤æ¬¡åè¦‹æª¢æŸ¥æ©Ÿåˆ¶

#### å°æ¨¡å‹æ€§èƒ½çš„è²¢ç»

1. **æ¨ç†èƒ½åŠ›æå‡**ï¼š
   - Private Score (0.72043) é¡¯è‘—é«˜æ–¼ Public Score (0.47177)
   - è­‰æ˜æ¨ç†éˆè¨“ç·´å°æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„é‡è¦æ€§
   - åœ¨æœªè¦‹éçš„æ¸¬è©¦é›†ä¸Šè¡¨ç¾æ›´ç©©å®š

2. **ä¸­ç«‹æ€§å¼·åŒ–**ï¼š
   - ç³»çµ±æ€§çš„å¤šè§’åº¦æ€è€ƒè¨“ç·´
   - åŸºæ–¼äº‹å¯¦çš„å®¢è§€åˆ†æèƒ½åŠ›
   - æ•æ„Ÿè­°é¡Œçš„å¹³è¡¡è™•ç†èƒ½åŠ›

3. **ç³»çµ±æ€§è¦†è“‹**ï¼š
   - å…¨é¢çš„ä¸»é¡Œå’Œé›£åº¦è¦†è“‹
   - æ¼¸é€²å¼çš„çŸ¥è­˜å»ºæ§‹
   - çµæ§‹åŒ–çš„èªçŸ¥æŒ‘æˆ¶

#### ä½¿ç”¨æ–¹æ³•

**å°å…¥N8Nå·¥ä½œæµç¨‹**ï¼š
```bash
# 1. å°‡workflow/DL_data_prepare_muti_topics_gen_repeat.jsonå°å…¥N8N
# 2. é…ç½®OpenAI APIæ†‘è­‰
# 3. èª¿æ•´è¼¸å‡ºè·¯å¾‘è¨­å®š
# 4. å•Ÿå‹•å·¥ä½œæµç¨‹
```

**è¨“ç·´æ¨¡å‹**ï¼š
```bash
python scripts/qwen_finetune_reasoning.py
```

**ç”Ÿæˆæäº¤æª”æ¡ˆ**ï¼š
```bash
python scripts/predict_test_reasoning_data_qwen2.5.py
```

### ç’°å¢ƒéœ€æ±‚

**è¨“ç·´ç’°å¢ƒ**ï¼š
- Python 3.8+
- PyTorch 2.0+
- Transformers 4.36+
- CUDA 11.8+ (RTX 4090æ¨è–¦)
- 24GB+ GPUè¨˜æ†¶é«”

**N8Nå·¥ä½œæµç¨‹ç’°å¢ƒ**ï¼š
- N8Nå¹³å°ï¼ˆè‡ªå»ºæˆ–é›²ç«¯ï¼‰
- OpenAI APIé‡‘é‘°ï¼ˆGPT-4æ¨è–¦ï¼‰
- è¶³å¤ çš„APIé…é¡
- ç©©å®šçš„ç¶²è·¯é€£æ¥

### é—œéµæŠ€è¡“å‰µæ–°

æœ¬å°ˆæ¡ˆçš„ä¸»è¦è²¢ç»åœ¨æ–¼ï¼š

1. **è‡ªå‹•åŒ–æ¨ç†æ•¸æ“šç”Ÿæˆ**ï¼šé¦–æ¬¡å°‡N8Nå·¥ä½œæµç¨‹æ‡‰ç”¨æ–¼å¤§è¦æ¨¡ä¸­æ–‡æ•æ„Ÿè­°é¡Œæ•¸æ“šç”Ÿæˆ
2. **çµæ§‹åŒ–æ¨ç†éˆ**ï¼šå‰µæ–°çš„XMLæ ¼å¼æ¨ç†éˆï¼Œé¡¯è‘—æå‡æ¨¡å‹æ¨ç†èƒ½åŠ›
3. **ç³»çµ±æ€§ä¸»é¡Œè¦†è“‹**ï¼š15å€‹æ•æ„Ÿä¸»é¡Œçš„å…¨é¢ç³»çµ±æ€§è™•ç†
4. **æ³›åŒ–èƒ½åŠ›é©—è­‰**ï¼šPrivate Scoreé é«˜æ–¼Public Scoreï¼Œè­‰æ˜æ¨ç†éˆè¨“ç·´çš„æœ‰æ•ˆæ€§

é€™äº›å‰µæ–°ç‚ºå¾ŒçºŒçš„Kaggle #3 GRPOè¨“ç·´å¥ å®šäº†å …å¯¦çš„æ•¸æ“šåŸºç¤ï¼Œä¸¦è­‰æ˜äº†è‡ªå‹•åŒ–å·¥ä½œæµç¨‹åœ¨AIè¨“ç·´æ•¸æ“šç”Ÿæˆä¸­çš„å·¨å¤§æ½›åŠ›ã€‚

### å¯¦éš›å¯¦ç¾ç‹€æ³

**é …ç›®ç›®éŒ„çµæ§‹**ï¼ˆå¯¦éš›æª”æ¡ˆç³»çµ±ï¼‰ï¼š
```
/home/ubuntu/DL/kaggle#2/
â”œâ”€â”€ è¨“ç·´æ¨¡å‹:
â”‚   â”œâ”€â”€ chinese_llm_mcq_model_qwen2.5_7b_reasoning/
â”‚   â”œâ”€â”€ chinese_llm_without_reasoning_qa_qwen2.5_14b/
â”‚   â””â”€â”€ deepseek_reasoning_deepseek_r1_14b_mixed/
â”œâ”€â”€ è¨“ç·´æ•¸æ“š:
â”‚   â”œâ”€â”€ formatted_train_data_reasoning.jsonl
â”‚   â”œâ”€â”€ deepseek_train_data_mixed.jsonl
â”‚   â””â”€â”€ formatted_train_data.jsonl
â”œâ”€â”€ è¨“ç·´è…³æœ¬:
â”‚   â”œâ”€â”€ qwen_finetune_reasoning.py
â”‚   â”œâ”€â”€ deepseek_finetune_reasoning.py
â”‚   â””â”€â”€ qwen_finetune_without_reasoning.py
â””â”€â”€ å¯¦é©—çµæœ:
    â”œâ”€â”€ results_reasoning/ (å¤šå€‹checkpoint)
    â”œâ”€â”€ results_reasoning_fast/
    â””â”€â”€ submission/submission_best_deepseek.csv
```

**å¯¦éš›è¨“ç·´æˆæœ**ï¼š
- **å¤šæ¨¡å‹ä¸¦è¡Œ**: åŒæ™‚è¨“ç·´Qwen2.5å’ŒDeepSeekæ¨¡å‹
- **æ¨ç†æ ¼å¼**: ä½¿ç”¨JSONLæ ¼å¼å­˜å„²æ¨ç†éˆæ•¸æ“š
- **æª¢æŸ¥é»ç®¡ç†**: æ¯å€‹æ¨¡å‹ä¿å­˜å¤šå€‹checkpointä¾¿æ–¼é¸æ“‡
- **ç«¶è³½æˆç¸¾**: Rank #30ï¼Œè­‰æ˜æ¨ç†æ–¹æ³•çš„æœ‰æ•ˆæ€§

**æŠ€è¡“ç‰¹é»**ï¼š
1. **æ¨ç†æ•¸æ“šæ ¼å¼**: JSONLè€ŒéXMLæ¨™ç±¤æ ¼å¼
2. **å¤šæ¨¡å‹ç­–ç•¥**: æ¢ç´¢ä¸åŒåŸºç¤æ¨¡å‹çš„æ•ˆæœ
3. **è¨“ç·´å„ªåŒ–**: å¯¦æ–½å¤šç¨®è¨˜æ†¶é«”å„ªåŒ–ç­–ç•¥

---

## KAGGLE #3: GRPO with Reasoning

### å¯¦éš›è¨“ç·´æ­·ç¨‹

**ç¬¬ä¸€éšæ®µè¨“ç·´** (grpo_0623):
- **æ¨¡å‹**: Qwen2.5-7B-Instruct
- **é€²åº¦**: åœ¨æ­¥é©Ÿ2312 (34%)æ™‚é‡åˆ°CUDAè¨˜æ†¶é«”å•é¡Œ
- **è§£æ±º**: æˆåŠŸå¾checkpoint-2200æ¢å¾©
- **è¼¸å‡º**: `submission_final_grpo_0623_checkpoint_2200.csv`

**ç¬¬äºŒéšæ®µè¨“ç·´** (grpo_chinese_50percent_0624):
- **æ•¸æ“š**: ä¸­æ–‡æ¨ç†æ•¸æ“š50%å­é›† (12,238å€‹preference pairs)
- **è¨“ç·´æ™‚é–“**: 39å°æ™‚44åˆ†é˜ (143,058ç§’)
- **ç¸½æ­¥æ•¸**: 5,506æ­¥ (å®Œæˆåº¦: 99.96%)
- **æœ€çµ‚æˆæœ**: **çå‹µåˆ†æ•¸0.66** ğŸ‰

**è©³ç´°è¨“ç·´çµ±è¨ˆ**ï¼š
```yaml
æœ€çµ‚è¨“ç·´æŒ‡æ¨™:
  train_loss: 0.058307682390680744
  reward_mean: 0.6604166527589163
  reward_std: 0.06803861757119496
  kl_divergence: 1.9039125045140584
  tokens_processed: 65,428,674
  
æ¨¡å‹ä¿å­˜:
  final_model: /home/ubuntu/DL/kaggle#3/models/grpo_chinese_50percent_0624/final_model
  checkpoints: 27å€‹ (æ¯200æ­¥ä¿å­˜)
  evaluation_samples: evaluation_samples.json
  training_config: training_config.json
```

### è¨“ç·´ç›£æ§èˆ‡åˆ†æ

![GRPOè¨“ç·´æŒ‡æ¨™](images/grpo_training_metrics.png)
*40å°æ™‚GRPOè¨“ç·´éç¨‹çš„å®Œæ•´ç›£æ§æŒ‡æ¨™*

**è¨“ç·´ç©©å®šæ€§åˆ†æ**ï¼š
- **æå¤±æ”¶æ–‚**ï¼šè¨“ç·´æå¤±å¾åˆæœŸçš„æ³¢å‹•é€æ¼¸ç©©å®šæ”¶æ–‚
- **å­¸ç¿’ç‡èª¿åº¦**ï¼šCosineå­¸ç¿’ç‡èª¿åº¦ç¢ºä¿ç©©å®šçš„è¨“ç·´éç¨‹
- **æ¢¯åº¦ç©©å®šæ€§**ï¼šæ¢¯åº¦ç¯„æ•¸ä¿æŒåœ¨åˆç†ç¯„åœï¼Œç„¡çˆ†ç‚¸æˆ–æ¶ˆå¤±
- **é•·æœŸç©©å®šæ€§**ï¼š40å°æ™‚é€£çºŒè¨“ç·´ç„¡ä¸­æ–·ï¼Œå±•ç¾å„ªç§€çš„ç³»çµ±ç©©å®šæ€§

### æ¨¡å‹éƒ¨ç½²èˆ‡åˆ†äº«

**HuggingFaceæ¨¡å‹ç™¼å¸ƒ**ï¼š
- **æ¨¡å‹å€‰åº«**: https://huggingface.co/RayTsai/chinese-grpo-qwen2.5-7b-50percent
- **ç™¼å¸ƒæ—¥æœŸ**: 2025å¹´6æœˆ28æ—¥
- **è¨“ç·´è³‡æ–™**: ä¸­æ–‡æ¨ç†æ•¸æ“š50%å­é›†ï¼ˆ12,238å€‹preference pairsï¼‰
- **åŸºç¤æ¨¡å‹**: Qwen/Qwen2.5-7B-Instruct
- **è¨“ç·´æ–¹æ³•**: GRPO with reasoning
- **ä¸»è¦ç‰¹è‰²**: 
  - ç¶“é40å°æ™‚GRPOè¨“ç·´çš„å„ªåŒ–æ¨¡å‹
  - å°ˆé–€é‡å°ä¸­æ–‡æ•æ„Ÿæ”¿æ²»è­°é¡Œé¸æ“‡é¡Œ
  - é”åˆ°0.66çš„çå‹µåˆ†æ•¸
  - æ”¯æ´4-bité‡åŒ–æ¨ç†

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "RayTsai/chinese-grpo-qwen2.5-7b-50percent"
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### GRPOæ ¸å¿ƒæŠ€è¡“å¯¦ç¾

**çå‹µå‡½æ•¸è¨­è¨ˆ**ï¼š
```python
def global_reward_function(prompts, completions):
    rewards = []
    for completion in completions:
        reward = 0.5  # åŸºç¤åˆ†æ•¸
        
        # æª¢æŸ¥ç­”æ¡ˆæ ¼å¼
        if any(marker in completion for marker in ["ç­”æ¡ˆï¼š", "Answer:"]):
            reward += 0.3
        
        # æª¢æŸ¥æ¨ç†èªªæ˜
        if any(marker in completion for marker in ["ç†ç”±ï¼š", "å› ç‚º", "æ ¹æ“š"]):
            reward += 0.2
        
        # å®Œæ•´ç­”æ¡ˆçå‹µ
        if extract_answer(completion) in ['A', 'B', 'C', 'D']:
            reward = max(reward, 0.7)
        
        rewards.append(min(1.0, reward))
    
    return torch.tensor(rewards)
```

**é—œéµå„ªåŒ–é…ç½®**ï¼š
```python
grpo_config = GRPOConfig(
    learning_rate=3e-05,
    per_device_train_batch_size=16,
    gradient_accumulation_steps=2,
    num_train_epochs=2,
    dataloader_num_workers=0,  # ğŸ”‘ è§£æ±ºPickleéŒ¯èª¤
    bf16=True,
    gradient_checkpointing=True
)
```

---

## å¯¦éš›è¨“ç·´çµæœå°æ¯”

### è¨“ç·´æ•ˆç‡å°æ¯”

| éšæ®µ | æ¨¡å‹ | è¨“ç·´æ™‚é–“ | è³‡æºä½¿ç”¨ | æˆæœ |
|------|------|----------|----------|------|
| **Kaggle #1** | Qwen2.5-14B | 38åˆ†é˜ | 20GB VRAM | Public: 0.62 |
| **Kaggle #2** | å¤šæ¨¡å‹ä¸¦è¡Œ | ~75åˆ†é˜ | 18-22GB | Rank #30 |
| **Kaggle #3** | GRPO Qwen2.5-7B | 2,400åˆ†é˜ | 22GB | Reward: 0.66 |

### æ€§èƒ½æ¼”é€²è¶¨å‹¢

```
æº–ç¢ºç‡è¡¨ç¾:
Kaggle #1: é«˜Publicï¼Œä½Private (éæ“¬åˆ)
Kaggle #2: å¹³è¡¡æå‡ï¼Œç«¶è³½æ’åé€²æ­¥
Kaggle #3: æŒçºŒå„ªåŒ–ï¼Œçå‹µåˆ†æ•¸ç©©å®šæå‡

è¨“ç·´ç©©å®šæ€§:
Kaggle #1: âœ… å¿«é€Ÿæ”¶æ–‚
Kaggle #2: âœ… å¤šæ¨¡å‹ä¸¦è¡Œç©©å®š
Kaggle #3: âš ï¸ éœ€è¦æª¢æŸ¥é»æ¢å¾©ï¼Œä½†æœ€çµ‚æˆåŠŸ
```

### é—œéµæŠ€è¡“çªç ´

1. **è¨˜æ†¶é«”ç®¡ç†**ï¼š
   - æˆåŠŸåœ¨24GBé¡¯å­˜é‹è¡Œ14Bæ¨¡å‹
   - 4-bité‡åŒ–ç¯€çœ60%è¨˜æ†¶é«”
   - è§£æ±ºé•·åºåˆ—OOMå•é¡Œ

2. **GRPOå„ªåŒ–**ï¼š
   - è§£æ±º`dataloader_num_workers=0`çš„PickleéŒ¯èª¤
   - å¯¦ç¾40å°æ™‚é•·æ™‚é–“ç©©å®šè¨“ç·´
   - é”åˆ°0.66çå‹µåˆ†æ•¸

3. **æ•¸æ“šè™•ç†**ï¼š
   - ä¸­æ–‡æ¨ç†æ•¸æ“šæˆåŠŸæ›¿ä»£ç¿»è­¯æ•¸æ“š
   - æ”¯æ´å¤šç¨®æ•¸æ“šæ ¼å¼ (TSV, JSONL, XML)

---

## æŠ€è¡“å‰µæ–°èˆ‡çªç ´

### 1. å®Œæ•´GRPOå¯¦ç¾

**å‰µæ–°é»**ï¼š
- é¦–æ¬¡åœ¨ä¸­æ–‡æ•æ„Ÿè­°é¡Œä¸Šæ‡‰ç”¨GRPO
- è¨­è¨ˆä¸­ç«‹æ€§æ„ŸçŸ¥çš„çå‹µå‡½æ•¸
- å¯¦ç¾40å°æ™‚é•·æ™‚é–“ç©©å®šè¨“ç·´

**æŠ€è¡“ç´°ç¯€**ï¼š
```python
# ä¸­ç«‹æ€§æª¢æ¸¬
def analyze_neutrality(text):
    bias_words = ["çµ•å°", "å¿…é ˆ", "å”¯ä¸€", "éŒ¯èª¤"]
    neutral_words = ["å¯èƒ½", "ç›¸å°", "ä¸åŒè§€é»", "å¹³è¡¡"]
    
    bias_score = sum(1 for word in bias_words if word in text)
    neutral_score = sum(1 for word in neutral_words if word in text)
    
    return (neutral_score - bias_score) / max(1, len(text.split()))
```

### 2. å·¥ç¨‹å„ªåŒ–å¯¦è¸

**PickleéŒ¯èª¤è§£æ±º**ï¼š
```python
# é—œéµè¨­ç½®
training_args = TrainingArguments(
    dataloader_num_workers=0,  # é¿å…å¤šé€²ç¨‹åºåˆ—åŒ–å•é¡Œ
    # å…¶ä»–é…ç½®...
)
```

**é‡è¤‡å­—ç¬¦æŠ‘åˆ¶**ï¼š
```python
generation_config = GenerationConfig(
    repetition_penalty=1.1,    # æ¸›å°‘é‡è¤‡ç”Ÿæˆ
    no_repeat_ngram_size=3,
    # å…¶ä»–é…ç½®...
)
```

### 3. è‡ªå‹•åŒ–ç›£æ§ç³»çµ±

**WandBæ•´åˆ**ï¼š
- é …ç›®ï¼šchinese-reasoning-grpo
- å¯¦æ™‚ç›£æ§ï¼šlossã€rewardã€KLæ•£åº¦
- è‡ªå‹•ä¿å­˜ï¼šæª¢æŸ¥é»å’Œé…ç½®

**æ—¥èªŒç³»çµ±**ï¼š
```
/home/ubuntu/DL/kaggle#3/logs/
â”œâ”€â”€ grpo_training_chinese_50percent_*.log
â”œâ”€â”€ training_progress_chinese_50percent_*.log
â””â”€â”€ training_errors_chinese_50percent_*.log
```

---

## æŒ‘æˆ°èˆ‡è§£æ±ºæ–¹æ¡ˆ

### 1. ç¡¬é«”è³‡æºé™åˆ¶

**æŒ‘æˆ°**ï¼š
- 24GBé¡¯å­˜é™åˆ¶
- é•·æ™‚é–“è¨“ç·´ç©©å®šæ€§
- å¤šæ¨¡å‹ä¸¦è¡Œç®¡ç†

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# è¨˜æ†¶é«”å„ªåŒ–ç­–ç•¥
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=BitsAndBytesConfig(load_in_4bit=True),
    device_map="auto",
    torch_dtype=torch.float16
)

# æ¢¯åº¦æª¢æŸ¥é»
model.gradient_checkpointing_enable()

# å‹•æ…‹æ‰¹é‡èª¿æ•´
effective_batch_size = batch_size * gradient_accumulation_steps
```

### 2. GRPOè¨“ç·´ç©©å®šæ€§

**æŒ‘æˆ°**ï¼š
- è¨“ç·´éç¨‹ä¸­æ–·
- çå‹µå‡½æ•¸è¨­è¨ˆ
- è¶…åƒæ•¸æ•æ„Ÿæ€§

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# æª¢æŸ¥é»ç­–ç•¥
save_steps = 200  # é »ç¹ä¿å­˜
save_total_limit = 3

# å­¸ç¿’ç‡èª¿æ•´
learning_rate = 3e-05  # ä¿å®ˆè¨­ç½®
warmup_steps = 50

# çå‹µå‡½æ•¸ç©©å®šæ€§
reward = torch.clamp(reward, min=0.1, max=1.0)
```

### 3. æ•¸æ“šè³ªé‡æ§åˆ¶

**æŒ‘æˆ°**ï¼š
- æ¨ç†éˆä¸€è‡´æ€§
- ä¸­æ–‡æ•¸æ“šå“è³ª
- æ ¼å¼æ¨™æº–åŒ–

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- å¤šè¼ªæ•¸æ“šé©—è­‰
- è‡ªå‹•æ ¼å¼æª¢æŸ¥
- äººå·¥æŠ½æ¨£å¯©æ ¸

---

## å„ªåŒ–å»ºè­°èˆ‡æœ€ä½³å¯¦è¸

### åŸºæ–¼å¯¦éš›ç¶“é©—çš„å»ºè­°

**1. æ¨¡å‹é¸æ“‡ç­–ç•¥**ï¼š
```
è³‡æºå……è¶³ â†’ Qwen2.5-14B (é«˜æº–ç¢ºç‡)
å¹³è¡¡è€ƒé‡ â†’ Qwen2.5-7B (æ€§åƒ¹æ¯”æœ€ä½³)
å¿«é€Ÿé©—è­‰ â†’ 7B + SFT (å¿«é€Ÿæ”¶æ–‚)
ä¸­ç«‹æ€§å„ªå…ˆ â†’ 7B + GRPO (æœ€ä½³ä¸­ç«‹æ€§)
```

**2. è¨“ç·´é…ç½®å„ªåŒ–**ï¼š
```yaml
# æœ€ä½³å¯¦è¸é…ç½®
model_config:
  quantization: 4bit_nf4
  lora_r: 16
  lora_alpha: 32

training_config:
  batch_size: 16
  gradient_accumulation: 2
  learning_rate: 3e-05
  num_epochs: 2
  
system_config:
  dataloader_num_workers: 0  # é—œéµï¼
  gradient_checkpointing: true
  bf16: true
```

**3. å¯¦é©—è¨­è¨ˆå»ºè­°**ï¼š
- å…ˆç”¨å°æ¨¡å‹é©—è­‰å¯è¡Œæ€§
- é »ç¹ä¿å­˜æª¢æŸ¥é»
- å¤šç¶­åº¦è©•ä¼°æŒ‡æ¨™
- è‡ªå‹•åŒ–ç›£æ§ç³»çµ±

### è³‡æºé…ç½®æŒ‡å—

**ç¡¬é«”éœ€æ±‚**ï¼š
- **æœ€ä½è¦æ±‚**ï¼šRTX 4070 16GB (7Bæ¨¡å‹)
- **æ¨è–¦é…ç½®**ï¼šRTX 4090 24GB (14Bæ¨¡å‹)
- **å°ˆæ¥­é…ç½®**ï¼šA100 40GB (æ›´å¤§æ‰¹é‡)

**æ™‚é–“è¦åŠƒ**ï¼š
- **SFT Simple**ï¼š1-2å°æ™‚
- **SFT Reasoning**ï¼š5-10å°æ™‚
- **GRPO**ï¼š20-40å°æ™‚

---

## çµè«–èˆ‡æœªä¾†å±•æœ›

### ä¸»è¦æˆå°±ç¸½çµ

1. **æŠ€è¡“çªç ´**ï¼š
   - æˆåŠŸåœ¨æ¶ˆè²»ç´šGPUå®Œæˆä¼æ¥­ç´šæ¨¡å‹è¨“ç·´
   - å¯¦ç¾ä¸­æ–‡GRPOè¨“ç·´ï¼Œé”åˆ°0.66çå‹µåˆ†æ•¸
   - å»ºç«‹å®Œæ•´çš„è¨“ç·´åˆ°è©•ä¼°æµç¨‹

2. **å¯¦ç”¨åƒ¹å€¼**ï¼š
   - æä¾›å¯è¤‡è£½çš„è¨“ç·´æ–¹æ¡ˆ
   - è§£æ±ºé—œéµæŠ€è¡“é›£é¡Œ
   - å»ºç«‹æœ€ä½³å¯¦è¸æŒ‡å—

3. **ç«¶è³½æˆæœ**ï¼š
   - Kaggle #2é”åˆ°Rank #30
   - é©—è­‰äº†æ¨ç†éˆæ–¹æ³•çš„æœ‰æ•ˆæ€§
   - GRPOæ–¹æ³•é¡¯è‘—æå‡æ¨¡å‹ä¸­ç«‹æ€§

4. **æ¨¡å‹é–‹æºè²¢ç»**ï¼š
   - æˆåŠŸç™¼å¸ƒGRPOè¨“ç·´æ¨¡å‹è‡³HuggingFace
   - æ¨¡å‹åœ°å€ï¼šhttps://huggingface.co/RayTsai/chinese-grpo-qwen2.5-7b-50percent
   - æä¾›å®Œæ•´çš„æ¨¡å‹æ¬Šé‡ä¾›ç¤¾å€ä½¿ç”¨
   - ä¿ƒé€²ä¸­æ–‡LLMæ¨ç†ç ”ç©¶çš„ç™¼å±•

### é—œéµç¶“é©—æ•™è¨“

**æˆåŠŸå› ç´ **ï¼š
- ç³»çµ±æ€§å¯¦é©—è¨­è¨ˆ
- æŒçºŒçš„æŠ€è¡“è¿­ä»£
- å®Œå–„çš„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
- åŸºæ–¼å¯¦éš›å•é¡Œçš„å„ªåŒ–

**æ”¹é€²ç©ºé–“**ï¼š
- å¢åŠ äººå·¥è©•ä¼°é©—è­‰
- æ“´å¤§æ¸¬è©¦æ•¸æ“šè¦æ¨¡
- æ¢ç´¢æ›´å¤šåŸºç·šæ¨¡å‹
- å„ªåŒ–è¨“ç·´æ•ˆç‡

### æœªä¾†ç ”ç©¶æ–¹å‘

**çŸ­æœŸç›®æ¨™** (1-3å€‹æœˆ)ï¼š
- å®Œå–„è‡ªå‹•åŒ–è©•ä¼°ç³»çµ±
- æ¸¬è©¦æ›´å¤šæ¨¡å‹çµ„åˆ
- å„ªåŒ–GRPOçå‹µå‡½æ•¸
- å»ºç«‹æ¨™æº–åŒ–æµç¨‹

**ä¸­æœŸç›®æ¨™** (3-12å€‹æœˆ)ï¼š
- æ¢ç´¢Constitutional AIæ–¹æ³•
- ç ”ç©¶Direct Preference Optimization
- é–‹ç™¼å¤šèªè¨€æ”¯æ´
- ç”¢æ¥­åŒ–æ‡‰ç”¨æ¢ç´¢

**é•·æœŸé¡˜æ™¯** (1å¹´+)ï¼š
- å»ºç«‹é–‹æºè©•ä¼°æ¨™æº–
- æ¨å‹•å­¸è¡“ç•Œåˆä½œ
- ç™¼è¡¨ç›¸é—œç ”ç©¶è«–æ–‡
- è²¢ç»ç¤¾å€æœ€ä½³å¯¦è¸

---

## é™„éŒ„

### A. å®Œæ•´æ–‡ä»¶æ¸…å–®

**ä»£ç¢¼æ–‡ä»¶**ï¼š
```
/home/ubuntu/DL/kaggle#2/
â”œâ”€â”€ qwen_finetune_reasoning.py
â”œâ”€â”€ deepseek_finetune_reasoning.py
â””â”€â”€ qwen_finetune_without_reasoning.py

/home/ubuntu/DL/kaggle#3/
â”œâ”€â”€ scripts/Train/grpo_training_chinese_50percent.py
â”œâ”€â”€ scripts/Train/run_chinese_50percent_training.sh
â””â”€â”€ scripts/Submission/grpo_test_submission.py
```

**æ•¸æ“šæ–‡ä»¶**ï¼š
```
/home/ubuntu/DL/kaggle#3/data/
â”œâ”€â”€ training_reasoning_data_chi.tsv (62.88MB)
â”œâ”€â”€ test-check-v2.csv (900é¡Œæ¸¬è©¦é›†)
â””â”€â”€ test-check-v2.tsv
```

**æ¨¡å‹æ–‡ä»¶**ï¼š
```
/home/ubuntu/DL/kaggle#3/models/
â”œâ”€â”€ grpo_0623/checkpoint-2200/
â””â”€â”€ grpo_chinese_50percent_0624/final_model/
```

### B. æŠ€è¡“è¦æ ¼

**LoRAé…ç½®**ï¼š
```json
{
  "r": 16,
  "lora_alpha": 32,
  "lora_dropout": 0.05,
  "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", 
                     "gate_proj", "up_proj", "down_proj"],
  "bias": "none"
}
```

**é‡åŒ–é…ç½®**ï¼š
```json
{
  "load_in_4bit": true,
  "bnb_4bit_compute_dtype": "float16",
  "bnb_4bit_quant_type": "nf4",
  "bnb_4bit_use_double_quant": true
}
```

### C. è¨“ç·´æ—¥èªŒæ‘˜è¦

**GRPOæœ€çµ‚è¨“ç·´çµ±è¨ˆ**ï¼š
- è¨“ç·´æ™‚é–“ï¼š143,058.0661ç§’ (39å°æ™‚44åˆ†é˜)
- æ¨£æœ¬é€Ÿåº¦ï¼š0.154 samples/second
- æ­¥é©Ÿé€Ÿåº¦ï¼š0.039 steps/second
- æœ€çµ‚Lossï¼š0.058307682390680744
- çå‹µåˆ†æ•¸ï¼š0.6604166527589163
- KLæ•£åº¦ï¼š1.9039125045140584

---

**å ±å‘Šå®Œæˆæ—¥æœŸ**ï¼š2025å¹´6æœˆ27æ—¥  
**åŸºæ–¼å¯¦éš›æ•¸æ“š**ï¼š40å°æ™‚GRPOè¨“ç·´ï¼ˆ50%è³‡æ–™é›†ï¼‰å®Œæ•´çµæœ  
**ä¸‹ä¸€æ­¥è¡Œå‹•**ï¼šä½¿ç”¨æœ€æ–°æ¨¡å‹ç”Ÿæˆæäº¤æ–‡ä»¶ä¸¦è©•ä¼°ç«¶è³½è¡¨ç¾